{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release frame and first movement: see other notebook\n",
    "\n",
    "### Example output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "('frame index predicted: ', 12)\n",
    "('real label:', 14.0)\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.96, 1.0, 0.03, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "('frame index predicted: ', 14)\n",
    "('real label:', 12.0)\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04, 0.53, 0.83, 0.99, 0.98, 0.19, 0.2, 0.13, 0.2, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.14, 0.01, 0.0]\n",
    "('frame index predicted: ', 11)\n",
    "('real label:', 15.0)\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45, 0.97, 0.99, 0.89, 0.71, 0.56, 0.07, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "('frame index predicted: ', 14)\n",
    "('real label:', 12.0)\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.98, 0.98, 0.01, 0.0, 0.0, 0.0, 0.0, 0.02, 0.04, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "('frame index predicted: ', 13)\n",
    "('real label:', 15.0)\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24, 0.7, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "('frame index predicted: ', 15)\n",
    "('real label:', 13.0)\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02, 1.0, 0.98, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "('frame index predicted: ', 13)\n",
    "('real label:', 16.0)\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.21, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "('frame index predicted: ', 16)\n",
    "('real label:', 11.0)\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03, 0.67, 0.94, 0.57, 0.1, 0.04, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "('frame index predicted: ', 11)\n",
    "('real label:', 12.0)\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13, 0.87, 0.99, 0.97, 0.97, 0.97, 0.22, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "('frame index predicted: ', 13)\n",
    "('real label:', 11.0)\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.57, 0.9, 1.0, 0.91, 0.2, 0.66, 0.83, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.01, 0.0]\n",
    "('frame index predicted: ', 11)\n",
    "('real label:', 12.0)\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21, 0.98, 0.32, 0.12, 0.07, 0.33, 0.72, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "('frame index predicted: ', 12)\n",
    "('real label:', 13.0)\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28, 0.89, 0.03, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "('frame index predicted: ', 13)\n",
    "('real label:', 14.0)\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.77, 1.0, 0.24, 0.0, 0.0, 0.0, 0.0, 0.07, 0.08, 0.04, 0.02, 0.0, 0.0, 0.01, 0.02, 0.03]\n",
    "('frame index predicted: ', 15)\n",
    "('real label:', 12.0)\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02, 0.0, 0.88, 0.98, 0.7, 0.1, 0.1, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "('frame index predicted: ', 11)\n",
    "('real label:', 14.0)\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 1.0, 1.0, 0.18, 0.0, 0.0, 0.0, 0.03, 0.03, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "('frame index predicted: ', 13)\n",
    "('real label:', 13.0)\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05, 0.98, 0.99, 0.93, 0.98, 0.95, 0.14, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "('frame index predicted: ', 13)\n",
    "('real label:', 12.0)\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.55, 0.95, 0.58, 0.47, 0.15, 0.03, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.44]\n",
    "('frame index predicted: ', 12)\n",
    "('Accuracy (only 1 frame later or earlier): ', 0.9528301886792453)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi person pose estimation \n",
    "\n",
    "* better acc than multi, aber wahrscheinlich nicht real time https://arxiv.org/abs/1701.01779 state of the art\n",
    "    * https://github.com/eldar/pose-tensorflow\n",
    "    * tensorflow implementation\n",
    "    * easy to start but need to install pyyaml\n",
    "* 3D: http://www.stat.ucla.edu/~sczhu/papers/Conf_2017/ICCV2017_3DPose.pdf probably also too slow\n",
    "* https://arxiv.org/pdf/1708.09182.pdf faster and maybe comparable to multi pose estimation\n",
    "    * can't find github\n",
    "* 3D aber wohl auch zu langsam https://link.springer.com/article/10.1007/s11042-017-5133-8\n",
    "* 3D with GIVEN 2D pose estimation: https://github.com/flyawaychase/3DHumanPose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batter analysis\n",
    "\n",
    "* What to predict? e.g. Hit into play?\n",
    "* detect bat in frames to get movement:\n",
    "    * problem: how to encode bounding box around bat?\n",
    "    * DETECTED IN 89/165 frames with thresh=0.4, no false positive\n",
    "    * DETECTED IN 111/165 frames with thresh = 0.4, only lots of sports ball and some glove false positive \n",
    "    * Time: each frame 0.25 s --> to slow, must be around 8 times faster\n",
    "    * change thresholds: nms doesn't change anything, other one a lot more detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ninawiedemann/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (253,254,255,256,257,258,259,289) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no' 'yes']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cf = pd.read_csv(\"/Users/ninawiedemann/Desktop/UNI/Praktikum/ALL/cf_data.csv\")\n",
    "print(np.unique(cf[\"Hit into play?\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "CLASSES = ('background',\n",
    "'person', 'bicycle', 'car','motorcycle','airplane','bus','train', 'truck', 'boat','traffic light',\n",
    "'fire hydrant', 'stop sign', 'parking meter', 'bench','bird','cat','dog','horse','sheep',\n",
    "'cow', 'elephant','bear','zebra','giraffe','hat','umbrella', 'handbag','tie','suitcase',\n",
    "'frisbee','skis','snowboard','sports ball','kite', 'baseball bat','baseball glove','skateboard','surfboard','tennis racket',\n",
    "'bottle','wine glass','cup','fork','knife','spoon','bowl','banana','apple','sandwich',\n",
    "'orange','broccoli','carrot','hot dog','pizza','donut','cake','chair','couch','potted plant',\n",
    "'bed','dining table','window','tv','laptop','mouse','remote','keyboard','cell phone','microwave',\n",
    "'oven', 'sink','refrigerator','blender','book','clock','vase','scissors','teddy bear','hair drier','tooth brush')\n",
    "\n",
    "MY_CLASSES = ('background', 'sports ball','baseball bat','baseball glove')\n",
    "\n",
    "def vis_detections(im, class_name, dets, thresh=0.4):\n",
    "    \"\"\"Draw detected bounding boxes.\"\"\"\n",
    "    inds = np.where(dets[:, -1] >= thresh)[0]\n",
    "    #if len(inds) == 0:\n",
    "    #    return\n",
    "\n",
    "    im = im[:, :, (2, 1, 0)]\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.imshow(im, aspect='equal')\n",
    "    for i in inds:\n",
    "        bbox = dets[i, :4]\n",
    "        score = dets[i, -1]\n",
    "\n",
    "        ax.add_patch(\n",
    "            plt.Rectangle((bbox[0], bbox[1]),\n",
    "                          bbox[2] - bbox[0],\n",
    "                          bbox[3] - bbox[1], fill=False,\n",
    "                          edgecolor='red', linewidth=3.5)\n",
    "            )\n",
    "        ax.text(bbox[0], bbox[1] - 2,\n",
    "                '{:s} {:.3f}'.format(class_name, score),\n",
    "                bbox=dict(facecolor='blue', alpha=0.5),\n",
    "                fontsize=14, color='white')\n",
    "\n",
    "    ax.set_title(('{} detections with '\n",
    "                  'p({} | box) >= {:.1f}').format(class_name, class_name,\n",
    "                                                  thresh),\n",
    "                  fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.draw()\n",
    "    plt.show()\n",
    "\n",
    "from os import listdir\n",
    "path = \"/Users/ninawiedemann/Desktop/UNI/Praktikum/py-faster-rcnn/tools/inputpic/\"\n",
    "# scores = np.load(path+\"/scores000542.jpg.npy\")\n",
    "# boxes = np.load(path+\"/boxes000542.jpg.npy\")\n",
    "detection_rate = 0\n",
    "print(listdir(path))\n",
    "for f in sorted(listdir(path)):\n",
    "    if f[0]!=\".\":\n",
    "        print(f)\n",
    "        im = plt.imread(path+f)\n",
    "        with open(\"/Users/ninawiedemann/Desktop/UNI/Praktikum/py-faster-rcnn/tools/outputpic/out\"+f[:-4], \"r\") as infile:\n",
    "            dets_dic = json.load(infile)\n",
    "        #print(dets_dic)\n",
    "        CONF_THRESH = 0.1\n",
    "\n",
    "        for cls_ind, cls in enumerate(MY_CLASSES[1:]):\n",
    "            # cls_ind += 1 # because we skipped background\n",
    "            # cls_boxes = boxes[:, 4*cls_ind:4*(cls_ind + 1)]\n",
    "            # cls_scores = scores[:, cls_ind]\n",
    "            # dets = np.hstack((cls_boxes,\n",
    "            #                   cls_scores[:, np.newaxis])).astype(np.float32)\n",
    "            # keep = nms(dets, NMS_THRESH)\n",
    "            try:\n",
    "                dets = dets_dic[cls]# dets[keep, :]\n",
    "                vis_detections(im, cls, np.array(dets), thresh=CONF_THRESH)\n",
    "                if cls == 'baseball bat':\n",
    "                    detection_rate+=1\n",
    "            except KeyError:\n",
    "                continue\n",
    "                #print(\"class not in image\", cls)\n",
    "print(\"Detected in \", detection_rate, \" frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV File with output of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns in CSV FILE:\n",
    "\n",
    "* PitchTypeAll: \n",
    "    * all  10 classes (only Eephus and Unknown Pitch Type are removed)\n",
    "    * trained on all players and all position\n",
    "    * about 60% accuracy on test data\n",
    "* Pitchtype_3classes_5player:\n",
    "    * classes only divided into Fastballs, Breaking Balls and Changeups\n",
    "    * trained on the 5 players with most pitches (Pitcher: [448802.0, 592314.0, 527054.0, 285079.0, 518693.0]\n",
    "    * trained on Windup and Stretch seperately and only results concatenated in csv\n",
    "        * Windup Acc: 0.87, 0.91 for these 5 players!\n",
    "        * Stretch Acc: 0.87, 0.79 for these 5 players!\n",
    "* Pitchtype_3classes_Allplayer\n",
    "    * same but trained on all players\n",
    "    * Windup Acc: 0.79 0.65\n",
    "    * Stretch Acc: 0.73, 0.6\n",
    "* Position CF: \n",
    "    * Pitching Position (Windup/Stretch) classification on all data\n",
    "    * on CF data\n",
    "    * Acc 0.96 0.96\n",
    "* Position SV: \n",
    "    * Pitching Position (Windup/Stretch) classification on all data\n",
    "    * on SV data\n",
    "    * Acc 0.94 0.93\n",
    "* Combined:\n",
    "    * Combining classification on all classes with the one on three classes:\n",
    "    * if they are not consistent: Replace prediction of PitchTypeAll classification with second best class\n",
    "    * improved Acc from 90 to 91 (but this also includes all training data, so it is a significant improvement - training acc is 1.00)\n",
    "\n",
    "\n",
    "SAVED MODELS: (test accuracy and balanced accuracy)\n",
    "* cf data, all pitch types: 0.64\n",
    "* cf data, 3 pitch types (fastball, breaking ball, changeup) only windup and 5 players with most pitches: 0.87, 0.91\n",
    "* cf data, 3 pitch types (fastball, breaking ball, changeup) only windup and  all players: 0.79 0.65\n",
    "* sv data, 3 pitch types (fastball, breaking ball, changeup) only windup and  all players: 0.6, 0.49\n",
    "* cf data, 3 pitch types (fastball, breaking ball, changeup) only Stretch and 5 players with most pitches: 0.87, 0.79\n",
    "* cf data, 3 pitch types (fastball, breaking ball, changeup) only Stretch and all players: 0.73, 0.6\n",
    "\n",
    "    \n",
    "PREDICT PITCHING POSITION (Stretch/Windup)\n",
    "* modelPosition: cf data: 0.96 0.96\n",
    "* modelPositionSV: sv data, 0.94 0.93\n",
    "\n",
    "PREDICT RELEASE FRAME:\n",
    "* on videos directly, predict from a range of the 80th until the 100th frame: 90% acc for a single frame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEETING NOTES\n",
    "\n",
    "* video to show field changes, cameras facing the sun, shadows\n",
    "* position on field\n",
    "* change json file\n",
    "* first movement pitcher and batter (first label with difference images and then train model)\n",
    "* filter for windup and stretch first is also possible (runner on 1st base)\n",
    "* center of gravity\n",
    "* weight different joints by their contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03599095344543457\n",
      "0.006043910980224609\n",
      "(167, 12, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "\n",
    "bsp = np.load(\"example.npy\")\n",
    "\n",
    "coordinates = [\"x\", \"y\"]\n",
    "joints_list = [\"right_shoulder\", \"left_shoulder\", \"right_elbow\", \"right_wrist\",\"left_elbow\", \"left_wrist\",\n",
    "        \"right_hip\", \"right_knee\", \"right_ankle\", \"left_hip\", \"left_knee\", \"left_ankle\", \"neck \", \n",
    "        \"right_eye\", \"right_ear\",\"left_eye\", \"left_ear\"]\n",
    "\n",
    "def to_json(play, first_move, release):\n",
    "    tic = time.time()\n",
    "    frames, joints, xy = bsp.shape\n",
    "    dic = {}\n",
    "    dic[\"timestamp\"] = time.time()\n",
    "    dic[\"device\"] = \"?\"\n",
    "    dic[\"deployment\"] = \"?\"\n",
    "    dic[\"frames\"] = []\n",
    "    for i in range(frames):\n",
    "        dic_joints = {}\n",
    "        for j in range(joints):\n",
    "            dic_xy = {}\n",
    "            for k in range(xy):\n",
    "                dic_xy[coordinates[k]] = bsp[i,j,k]\n",
    "            dic_joints[joints_list[j]] = dic_xy\n",
    "        dic_joints[\"events\"]=[]\n",
    "        if i==first_move:\n",
    "            dic_joints[\"events\"].append({\"timestamp\": time.time(), \"name\": \"Pitcher's first movement\",\"code\": 1,\n",
    "                                    \"target_name\": \"Pitcher\", \"target_id\": 1})\n",
    "        if i ==release:\n",
    "            dic_joints[\"events\"].append({\"timestamp\": time.time(), \"name\": \"Pitcher ball release\",\"code\": 2,\n",
    "                                    \"target_name\": \"Pitcher\", \"target_id\": 1})\n",
    "        dic[\"frames\"].append(dic_joints)\n",
    "        \n",
    "    with open(\"test_json_format.json\", 'w') as outfile:\n",
    "        json.dump(dic, outfile, indent=10)\n",
    "    print(time.time()-tic)\n",
    "        \n",
    "        \n",
    "to_json(bsp, 2, 4)\n",
    "\n",
    "def from_json(file):\n",
    "    tic = time.time()\n",
    "    with open(file, 'r') as inf:\n",
    "        out = json.load(inf)\n",
    "\n",
    "    liste = []\n",
    "    for fr in out[\"frames\"]:\n",
    "        l_joints = []\n",
    "        for j in joints_list[:12]:\n",
    "            l_coo = []\n",
    "            for xy in coordinates:\n",
    "                l_coo.append(fr[j][xy])\n",
    "            l_joints.append(l_coo)\n",
    "        liste.append(l_joints)\n",
    "\n",
    "    print(time.time()-tic)\n",
    "    return np.array(liste)\n",
    "\n",
    "arr = from_json(\"test_json_format.json\")\n",
    "\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
