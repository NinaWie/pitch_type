{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practise Pandas and clean merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"/Users/ninawiedemann/Desktop/UNI/Praktikum/merge_16.csv\")\n",
    "# print(file.columns.tolist())\n",
    "# print(file[\"Extension (P)\"][4])\n",
    "# file.dtypes()\n",
    "# print(file.head())\n",
    "# f체r array nur von den Daten: file.values()\n",
    "# file.sort_index(axis = 1, ascending = True) //um 체berschriften zu sortieren zb nach alphabet\n",
    "#sorted = file.sort_values(by = \"Extension (P)\")\n",
    "# print(a[\"Extension (P)\"])\n",
    "# f체r statistics also mean std usw: file.describe()\n",
    "# print(file[0:3])\n",
    "# mehrere spalten ausw채hlen: file.loc[:, ['A','B']]\n",
    "\n",
    "\n",
    "# a= df['Extension (P)'].values\n",
    "# print(a)\n",
    "# print(np.any(np.isnan(a)))\n",
    "\n",
    "df = df.sort_values(by = \"Backspin Rate (P)\")\n",
    "print(df[\"Backspin Rate (P)\"])\n",
    "for i in range(2289,2269, -1):\n",
    "    df = df.drop(df.index[[i]])\n",
    "print(df[\"Backspin Rate (P)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "koord = df.iloc[:,df.columns.get_loc(\"0\"):df.columns.get_loc(\"159\")]\n",
    "\n",
    "\"\"\"clean data by deleting nan columns\"\"\"\n",
    "for col in df.columns.tolist():\n",
    "    if (type(df[col][0]) is not np.float64 and type(df[col][0]) is not np.int64) or np.any(np.isnan(df[col].values)):\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "for col in koord.columns.tolist():\n",
    "    df[col]=koord[col]\n",
    "\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/ninawiedemann/Desktop/UNI/Praktikum/merge_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl = pd.read_csv(\"/Users/ninawiedemann/Desktop/UNI/Praktikum/merge_clean.csv\")\n",
    "#print(cl.columns.tolist())\n",
    "#print(cl[\"0\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf = pd.read_csv(\"/Users/ninawiedemann/Desktop/UNI/Praktikum/cf_data.csv\")\n",
    "sv = pd.read_csv(\"/Users/ninawiedemann/Desktop/UNI/Praktikum/sv_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get coordinate values and pitch type labels seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coordinates = cf.iloc[:,cf.columns.get_loc(\"0\"):cf.columns.get_loc(\"166\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique  = np.unique(cf[\"Pitch Type\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def oneHot(dataframe, column):\n",
    "    unique  = np.unique(dataframe[column].values)\n",
    "    l = len(dataframe.index)\n",
    "    loc = dataframe.columns.get_loc(column)\n",
    "    labels = np.zeros((l, 12))\n",
    "    for i in range(l):\n",
    "        #print(cf.iloc[i,loc])\n",
    "        pitch = dataframe.iloc[i,loc]\n",
    "        ind = unique.tolist().index(pitch)\n",
    "        labels[i, ind] = 1\n",
    "    return labels, unique\n",
    "\n",
    "labels, _ = oneHot(cf, \"Pitch Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_array = coordinates.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change pandas dataframe to np.array\n",
    "(Problem: missing values in den Koordinaten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M, N = data_array.shape\n",
    "data = np.zeros((M,N,18,2))\n",
    "\n",
    "for i in range(M):\n",
    "    for j in range(N):\n",
    "        if not pd.isnull(data_array[i,j]):\n",
    "            data[i,j]=np.array(eval(data_array[i,j]))\n",
    "\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing = pd.isnull(data_array)\n",
    "print(\"Ratio missing: \", np.count_nonzero(missing)/(M*N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow conv net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = data[:13000,:]\n",
    "test_x = data[13000:, :]\n",
    "train_t= labels[:13000,:]\n",
    "test_t = labels[13000:, :]\n",
    "\n",
    "print(len(train_x))\n",
    "print(len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, N, 18, 2), name = \"input\")\n",
    "x_ = tf.reshape(x, (-1, N, 36 ,1))\n",
    "y = tf.placeholder(tf.float32, (None, len(labels[0])))\n",
    "\n",
    "net = tf.layers.conv2d(x_, filters=16, kernel_size=5, strides=2, activation=tf.nn.relu)\n",
    "net = tf.layers.conv2d(net, filters=16, kernel_size=3, strides=1, activation=tf.nn.relu)\n",
    "net = tf.layers.conv2d(net, filters=32, kernel_size=3, strides=1, activation=tf.nn.relu)\n",
    "net = tf.layers.conv2d(net, filters=1, kernel_size=1)\n",
    "shapes = net.get_shape().as_list()\n",
    "ff = tf.reshape(net, (-1, shapes[1]*shapes[2]))\n",
    "ff = tf.layers.dense(ff, 128, activation = tf.nn.relu)\n",
    "ff = tf.layers.dense(ff, len(labels[0]), activation = tf.nn.sigmoid)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y-ff))\n",
    "optimizer = tf.train.AdamOptimizer(0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batches(x, y, batchsize=32):\n",
    "    permute = np.random.permutation(len(x))\n",
    "    for i in range(0, len(x)-batchsize, batchsize):\n",
    "        indices = permute[i:i+batchsize]\n",
    "        yield x[indices], y[indices]\n",
    "    \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Run session for 2000 epochs\n",
    "for epoch in range(2000 + 1):\n",
    "    for batch_x, batch_t in batches(train_x, train_t, 32):\n",
    "        sess.run(optimizer, {x: batch_x, y: batch_t})\n",
    "    print(epoch, sess.run(loss, {x: test_x, y: test_t}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sess.run(loss, {x: test_x, y: test_t}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decode_one_hot(results):\n",
    "    \"\"\"takes the maximum value and gets the corresponding pitch type\n",
    "    input: array of size trials * pitchTypesNr\n",
    "    returns: array of size trials containing the pitch type as a string\n",
    "    \"\"\"\n",
    "    unique  = np.unique(cf[\"Pitch Type\"].values)\n",
    "    p = []\n",
    "    for pitch, i in enumerate(results):\n",
    "        ind = np.argmax(pitch)\n",
    "        p.append(unique[ind])\n",
    "    return p\n",
    "\n",
    "testing = sess.run(ff, {x: test_x, y: test_t})\n",
    "pitches = decode_one_hot(testing)\n",
    "label_pitches = (cf[\"Pitch Type\"].values)[13000:]\n",
    "\n",
    "# evaluate error rate\n",
    "right = 0\n",
    "wrong = 0\n",
    "for i in range(len(pitches)):\n",
    "    if pitches[i]==label_pitches[i]:\n",
    "        right+=1\n",
    "    else:\n",
    "        wrong+=1\n",
    "print(right/(right+wrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oneHot(dataframe, column):\n",
    "    unique  = np.unique(dataframe[column].values)\n",
    "    l = len(dataframe.index)\n",
    "    loc = dataframe.columns.get_loc(column)\n",
    "    labels = np.zeros((l, 12))\n",
    "    for i in range(l):\n",
    "        #print(cf.iloc[i,loc])\n",
    "        pitch = dataframe.iloc[i,loc]\n",
    "        ind = unique.tolist().index(pitch)\n",
    "        labels[i, ind] = 1\n",
    "    return labels, unique\n",
    "\n",
    "def decode_one_hot(results, unique):\n",
    "    \"\"\"takes the maximum value and gets the corresponding pitch type\n",
    "    input: array of size trials * pitchTypesNr\n",
    "    returns: array of size trials containing the pitch type as a string\n",
    "    \"\"\"\n",
    "    #unique  = np.unique(cf[\"Pitch Type\"].values)\n",
    "    p = []\n",
    "    print(results)\n",
    "    for i, pitch in enumerate(results):\n",
    "        #print(pitch)\n",
    "        ind = np.argmax(pitch)\n",
    "        #print(ind)\n",
    "        p.append(unique[ind])\n",
    "    return p\n",
    "\n",
    "labels, unique = oneHot(frame, \"Pitch Type\")\n",
    "\n",
    "new = decode_one_hot(labels, unique)\n",
    "print(np.sum(new==frame[\"Pitch Type\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only pitcher "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/ninawiedemann/Desktop/UNI/Praktikum/cf_data.csv\")\n",
    "#df = df.sort_values(by = \"Player\") # Ball Picther or Strike outcome pitcher\n",
    "# bis 8615 ball/pitcher\n",
    "pitcher = df.loc[frame[\"Player\"]==\"Pitcher\"]\n",
    "pitcher.to_csv(\"/Users/ninawiedemann/Desktop/UNI/Praktikum/cf_only_pitcher.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame = pd.read_csv(\"/Users/ninawiedemann/Desktop/UNI/Praktikum/cf_only_pitcher.csv\")\n",
    "print(len(frame[\"Player\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = frame.loc[frame[\"Player\"]==\"Pitcher\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(a.iloc[650, a.columns.get_loc(\"Player\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr1 = ([\"hi\", \"ni\", \"gu\"])\n",
    "arr2 = ([\"hi\", \"nina\", \"gu\"])\n",
    "arr3 = np.asarray(arr1)==np.asarray(arr2)\n",
    "print(arr3)\n",
    "print(np.sum(arr3))\n",
    "\n",
    "print(type(frame[\"Player\"].values[6000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf = pd.read_csv(\"/Users/ninawiedemann/Desktop/UNI/Praktikum/cf_only_pitcher.csv\")\n",
    "\n",
    "print(\"csv eingelesen\")\n",
    "# COORDINATES\n",
    "coordinates = cf.iloc[:,cf.columns.get_loc(\"0\"):cf.columns.get_loc(\"166\")]\n",
    "data_array = coordinates.values\n",
    "M, N = data_array.shape\n",
    "data = np.zeros((M,N,18,2))\n",
    "\n",
    "c=0\n",
    "for i in range(M):\n",
    "    for j in range(N):\n",
    "        if not pd.isnull(data_array[i,j]):\n",
    "            data[i,j]=np.array(eval(data_array[i,j]))\n",
    "        else:\n",
    "            c+=1\n",
    "\n",
    "np.save(\"coord_array\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SEP = 6000\n",
    "EPOCHS = 30\n",
    "\n",
    "print(\"imports\")\n",
    "cf = pd.read_csv(\"/Users/ninawiedemann/Desktop/UNI/Praktikum/cf_only_pitcher.csv\")\n",
    "\n",
    "print(\"csv eingelesen\")\n",
    "# COORDINATES\n",
    "\"\"\"\n",
    "coordinates = cf.iloc[:,cf.columns.get_loc(\"0\"):cf.columns.get_loc(\"166\")]\n",
    "data_array = coordinates.values\n",
    "M, N = data_array.shape\n",
    "data = np.zeros((M,N,18,2))\n",
    "\n",
    "c=0\n",
    "for i in range(M):\n",
    "    for j in range(N):\n",
    "        if not pd.isnull(data_array[i,j]):\n",
    "            data[i,j]=np.array(eval(data_array[i,j]))\n",
    "        else:\n",
    "            c+=1\n",
    "print(\"nan in daten:\",c)\n",
    "\"\"\"\n",
    "\n",
    "data = np.load(\"coord_array.npy\")\n",
    "M,N, _,_ = data.shape\n",
    "\n",
    "# LABELS\n",
    "def oneHot(dataframe, column):\n",
    "    unique  = np.unique(dataframe[column].values)\n",
    "    l = len(dataframe.index)\n",
    "    loc = dataframe.columns.get_loc(column)\n",
    "    labels = np.zeros((l, 12))\n",
    "    for i in range(l):\n",
    "        #print(cf.iloc[i,loc])\n",
    "        pitch = dataframe.iloc[i,loc]\n",
    "        ind = unique.tolist().index(pitch)\n",
    "        labels[i, ind] = 1\n",
    "    return labels, unique\n",
    "\n",
    "def decode_one_hot(results, unique):\n",
    "    \"\"\"takes the maximum value and gets the corresponding pitch type\n",
    "    input: array of size trials * pitchTypesNr\n",
    "    returns: array of size trials containing the pitch type as a string\n",
    "    \"\"\"\n",
    "    #unique  = np.unique(cf[\"Pitch Type\"].values)\n",
    "    p = []\n",
    "    for _, pitch in enumerate(results):\n",
    "        ind = np.argmax(pitch)\n",
    "        p.append(unique[ind])\n",
    "    return p\n",
    "\n",
    "labels, unique = oneHot(cf, \"Pitch Type\")\n",
    "label_pitches = (cf[\"Pitch Type\"].values)[SEP:]\n",
    "\n",
    "# NET\n",
    "\n",
    "np.save(\"labels\", labels)\n",
    "np.save(\"unique\", unique)\n",
    "np.save(\"label_pitches\", label_pitches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/ninawiedemann/Desktop/UNI/Praktikum/merge_16.csv\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.loc[df[\"Player\"] == \"Pitcher\"]\n",
    "coordina = df.iloc[:, df.columns.get_loc(\"0\"):df.columns.get_loc(\"159\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M, N = coordina.values.shape\n",
    "SEP = int(M*0.9)\n",
    "print(\"The training data will be up to %d and the test data from %d to %d\"%(SEP, SEP, M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pointer = df.columns.get_loc(\"0\")\n",
    "columns = df.columns.tolist()\n",
    "start = pointer\n",
    "while(True):\n",
    "    try:\n",
    "        zahl = int(columns[pointer])\n",
    "        pointer+=1\n",
    "    except ValueError:\n",
    "        break\n",
    "\n",
    "coord = df.iloc[:, start:pointer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing and balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "cf = pd.read_csv(\"merge_16.csv\")\n",
    "cf = cf[cf[\"Player\"]==\"Pitcher\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.stats\n",
    "\n",
    "print(np.unique(cf[\"Pitch Type\"].values))\n",
    "\n",
    "types = cf[\"Pitch Type\"].values\n",
    "note_frequency = sp.stats.itemfreq(types)\n",
    "print(note_frequency)\n",
    "smaller_20 = (note_frequency[np.where(note_frequency[:,1]<30)])[:,0].flatten()\n",
    "\n",
    "for typ in smaller_20:\n",
    "    cf = cf.drop(cf[cf[\"Pitch Type\"]==typ].index)\n",
    "\n",
    "\n",
    "print(np.unique(cf[\"Pitch Type\"].values))\n",
    "#cf = cf.drop(cf[cf[\"Pitch Type\"]=='Fastball (Split-finger)' or cf[\"Pitch Type\"]==\"Unknown Pitch Type\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr = np.load(\"coord_array.npy\")\n",
    "print(np.any(np.isnan(arr)))\n",
    "means = np.mean(arr, axis = 1)\n",
    "std = np.std(arr, axis = 1)\n",
    "res = np.asarray([(arr[:,i]-means)/(std+0.0001) for i in range(len(arr[0]))])\n",
    "new = np.swapaxes(res, 0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "data = compute_class_weight(\"auto\", np.unique(cf[\"Pitch Type\"].values),cf[\"Pitch Type\"].values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_string= cf[\"Pitch Type\"].values\n",
    "unique =np.unique(labels_string)\n",
    "#print(np.unique(pitches))\n",
    "#print(np.sum(data))\n",
    "nr_classes=len(unique)\n",
    "ex_per_class = 4\n",
    "\n",
    "\"\"\"liste=np.zeros((7,4))\n",
    "for i, types in enumerate(np.unique(pitches)):\n",
    "    liste[i] = (np.random.choice(np.where(pitches==types)[0], 4))\n",
    "print(liste)\n",
    "\"\"\"\n",
    "index_liste = []\n",
    "for pitches in unique:\n",
    "    index_liste.append(np.where(labels_string==pitches))\n",
    "    \n",
    "def balanced_batches(y):   \n",
    "    for j in range(5):\n",
    "        liste=np.zeros((nr_classes, ex_per_class))\n",
    "        for i in range(nr_classes):\n",
    "            liste[i] = np.random.choice(index_liste[i][0], ex_per_class)\n",
    "        #print(liste.flatten().astype(int))\n",
    "        yield y[liste.flatten().astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for batch_x in balanced_batches(labels_string):\n",
    "    print(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from data_preprocess import Preprocessor\n",
    "\n",
    "def decode_one_hot(results, unique):\n",
    "    \"\"\"takes the maximum value and gets the corresponding pitch type\n",
    "    input: array of size trials * pitchTypesNr\n",
    "    returns: array of size trials containing the pitch type as a string\n",
    "    \"\"\"\n",
    "    #unique  = np.unique(cf[\"Pitch Type\"].values)\n",
    "    p = []\n",
    "    for _, pitch in enumerate(results):\n",
    "        ind = np.argmax(pitch)\n",
    "        if pitch[ind]>0.5:\n",
    "            p.append(unique[ind])\n",
    "        else:\n",
    "            p.append(\"Too small\")\n",
    "    return p\n",
    "\n",
    "leaky_relu = lambda x: tf.maximum(0.2*x, x)\n",
    "\n",
    "\n",
    "ex_per_class = 4\n",
    "EPOCHS = 10\n",
    "PATH = \"/Users/ninawiedemann/Desktop/UNI/Praktikum/sv_data.csv\"\n",
    "LABELS = \"Pitch Type\"\n",
    "act = leaky_relu\n",
    "CUT_OFF_Classes = 60\n",
    "\n",
    "prepro = Preprocessor(PATH, CUT_OFF_Classes)\n",
    "data = np.load(\"coord_sv.npy\") #prepro.get_coord_arr(\"coord_sv.npy\")\n",
    "\n",
    "M,N,nr_joints,_ = data.shape\n",
    "SEP = int(M*0.9)\n",
    "\n",
    "labels, unique = prepro.get_labels_onehot(LABELS)\n",
    "labels_string = prepro.get_labels(LABELS)\n",
    "#labels_test = decode_one_hot(labels[SEP:, :], unique)\n",
    "\n",
    "nr_classes = len(np.unique(labels_string))\n",
    "BATCHSIZE = nr_classes*ex_per_class\n",
    "print(\"nr classes\", nr_classes, \"Batchsize\", BATCHSIZE)\n",
    "\n",
    "# NET\n",
    "\n",
    "ind = np.random.permutation(len(data))\n",
    "train_ind = ind[:SEP]\n",
    "test_ind = ind[SEP:]\n",
    "\n",
    "train_x = data[train_ind]\n",
    "test_x = data[test_ind]\n",
    "train_t= labels[train_ind]\n",
    "test_t = labels[test_ind]\n",
    "labels_string_train = labels_string[train_ind]\n",
    "labels_string_test = labels_string[test_ind]\n",
    "\n",
    "\"\"\"\n",
    "DATA TESTING:\n",
    "indiuh = np.where(ind==2000)\n",
    "print(\"Labels nach preprocc von 2000\", labels_string[2000])\n",
    "print(\"new Index of 2000\", indiuh, \"test ob where funkt: \", ind[indiuh])\n",
    "print(\"train coord of 2000 u 140\", train_x[indiuh, 140])\n",
    "print(\"labels_string von 2000\", labels_string_train[indiuh])\n",
    "print(\"one hot von 2000\", train_t[indiuh])\n",
    "\"\"\"\n",
    "\n",
    "index_liste = []\n",
    "for pitches in unique:\n",
    "    index_liste.append(np.where(labels_string_train==pitches))\n",
    "\n",
    "len_test = len(test_x)\n",
    "len_train = len(train_x)\n",
    "print(\"Test set size: \", len_test, \" train set size: \", len_train)\n",
    "print(\"Shapes of train_x\", train_x.shape, \"shape of test_x\", test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normal conv net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, N, nr_joints, 2), name = \"input\")\n",
    "x_ = tf.reshape(x, (-1, N, nr_joints*2))\n",
    "y = tf.placeholder(tf.float32, (None, len(labels[0])))\n",
    "\n",
    "net = tf.layers.conv1d(x_, filters=256, kernel_size=5, strides=2, activation=act)\n",
    "net = tf.layers.conv1d(net, filters=256, kernel_size=3, strides=1, activation=act)\n",
    "net = tf.layers.conv1d(net, filters=128, kernel_size=3, strides=1, activation=act)\n",
    "net = tf.layers.conv1d(net, filters=1, kernel_size=1, activation = act)\n",
    "shapes = net.get_shape().as_list()\n",
    "ff = tf.reshape(net, (-1, shapes[1]*shapes[2]))\n",
    "ff = tf.layers.dense(ff, 1024, activation = act)\n",
    "ff = tf.layers.dense(ff, 128, activation = act)\n",
    "logits = tf.layers.dense(ff, len(labels[0]), activation = None)\n",
    "out = tf.nn.softmax(logits)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits)) # tf.reduce_mean(tf.square(y-ff))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = BATCHSIZE\n",
    "display_step = 10\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Network Parameters\n",
    "n_input = nr_joints*2 # MNIST data input (img shape: 28*28)\n",
    "n_steps = N # timesteps\n",
    "n_hidden = 128 # hidden layer num of features\n",
    "n_classes = 12 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x_ = tf.placeholder(\"float\", [None, n_steps, nr_joints, 2])\n",
    "x = tf.reshape(x_, (-1, N, nr_joints*2))\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "\"\"\"# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "def RNN(x):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, n_steps, 1)\n",
    "    \n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    \"\"\"with tf.variable_scope(\"myrnn\") as scope:\n",
    "        for i in range(n_steps-1):\n",
    "            if i > 0:\n",
    "                scope.reuse_variables()\n",
    "            output, state = lstm_cell(x[i], state)\"\"\"\n",
    "\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.layers.dense(outputs[-1], n_classes)   #tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "out_logits = RNN(x)\n",
    "out = tf.nn.softmax(out_logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out_logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi layer lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = BATCHSIZE\n",
    "display_step = 10\n",
    "nr_layers = 4\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Network Parameters\n",
    "n_input = nr_joints*2 # MNIST data input (img shape: 28*28)\n",
    "n_steps = N # timesteps\n",
    "n_hidden = 128 # hidden layer num of features\n",
    "n_classes = 12 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x_ = tf.placeholder(\"float\", [None, n_steps, nr_joints, 2])\n",
    "x = tf.reshape(x_, (-1, N, nr_joints*2))\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "\"\"\"# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "def RNN(x):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, n_steps, 1)\n",
    "    \n",
    "    # Define a lstm cell with tensorflow\n",
    "    #lstm_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    \n",
    "    def lstm_cell():\n",
    "          return rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    \n",
    "    stacked_lstm = tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(nr_layers)])\n",
    "\n",
    "\n",
    "    # Get lstm cell output\n",
    "    \"\"\"with tf.variable_scope(\"myrnn\") as scope:\n",
    "        for i in range(n_steps-1):\n",
    "            if i > 0:\n",
    "                scope.reuse_variables()\n",
    "            output, state = lstm_cell(x[i], state)\"\"\"\n",
    "\n",
    "    outputs, states = rnn.static_rnn(stacked_lstm, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.layers.dense(outputs[-1], n_classes)   #tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "out_logits = RNN(x)\n",
    "out = tf.nn.softmax(out_logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out_logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batches(x, y, batchsize=32):\n",
    "    permute = np.random.permutation(len(x))\n",
    "    for i in range(0, len(x)-batchsize, batchsize):\n",
    "        indices = permute[i:i+batchsize]\n",
    "        yield x[indices], y[indices]\n",
    "\n",
    "def balanced_batches(x, y, batchsize=32):\n",
    "    for j in range(200):\n",
    "        liste=np.zeros((nr_classes, ex_per_class))\n",
    "        for i in range(nr_classes):\n",
    "            # print(j, i, np.random.choice(index_liste[i][0], ex_per_class))\n",
    "            liste[i] = np.random.choice(index_liste[i][0], ex_per_class, replace=False)\n",
    "        liste = liste.flatten().astype(int)\n",
    "        yield x[liste], y[liste]\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Run session for EPOCH epochs\n",
    "for epoch in range(EPOCHS + 1):\n",
    "    for batch_x, batch_t in balanced_batches(train_x, train_t, BATCHSIZE):\n",
    "        sess.run(optimizer, {x_: batch_x, y: batch_t})\n",
    "    # print(\"Loss test: \", sess.run(loss, {x: test_x, y: test_t}))\n",
    "    #print(\"Loss train: \", sess.run(loss, {x: train_x, y: train_t}))\n",
    "\n",
    "    #Test Accuracy\n",
    "    loss_test, out_test = sess.run([loss,out], {x_: test_x, y: test_t})\n",
    "    print(\"Loss test\", loss_test)\n",
    "    pitches_test = decode_one_hot(out_test, unique)\n",
    "    print(\"Accuracy test: \", np.sum(np.asarray(labels_string_test)==pitches_test)/len_test)\n",
    "    \n",
    "    #Train Accuracy\n",
    "    out_train = sess.run(out, {x_: train_x, y: train_t})\n",
    "    pitches_train = decode_one_hot(out_train, unique)\n",
    "    print(\"Accuracy train: \", np.sum(np.asarray(labels_string_train)==pitches_train)/SEP)\n",
    "\n",
    "print(pitches_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cut file to stretch and pitch type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "out_list = [\"ine\", \"ine\", \"bdeu\", \"hdba\", \"nina\", \"nina\"]\n",
    "ground_truth_list = [\"ine\",\"ine\", \"bdeu\", \"ine\", \"nina\", \"halo\"]\n",
    "\n",
    "out = np.array(out_list)\n",
    "ground_truth = np.array(ground_truth_list)\n",
    "\n",
    "same = out[np.where(out==ground_truth)[0]]\n",
    "\n",
    "right_frequency = sp.stats.itemfreq(same)\n",
    "total_frequency = sp.stats.itemfreq(ground_truth)\n",
    "right_dict = dict(zip(right_frequency[:,0], right_frequency[:,1]))\n",
    "total_dict = dict(zip(total_frequency[:,0], total_frequency[:,1]))\n",
    "\n",
    "acc= right_dict\n",
    "for types in right_dict.keys():\n",
    "    acc[types] = (int(right_dict[types])/float(total_dict[types]))\n",
    "\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cf = np.load(\"coord_array.npy\")\n",
    "#sv = np.load(\"coord_sv.npy\")\n",
    "#print(cf.shape, sv.shape)\n",
    "\n",
    "cf = pd.read_csv(\"cf_data.csv\")\n",
    "sv = pd.read_csv(\"sv_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf = cf[cf[\"Player\"]==\"Pitcher\"]\n",
    "sv = sv[sv[\"Player\"]==\"Pitcher\"]\n",
    "cf_plays = cf['play_id'].values\n",
    "print(sv[sv[\"play_id\"]==cf_plays[0]].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cf_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sv[\"play_id\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "common_ids = []\n",
    "sv_plays = sv[\"play_id\"].values\n",
    "for i, ids in enumerate(cf_plays):\n",
    "    if ids in sv_plays:\n",
    "        common_ids.append(ids)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(common_ids))\n",
    "print(len(sv_plays))\n",
    "print(len(cf_plays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cf[\"play_id\"].values[0])\n",
    "new = cf[cf[\"play_id\"] in sv[\"play_id\"].values]\n",
    "print((np.array(sv_plays)==np.array(cf_plays)))\n",
    "print(np.where(np.array(sv_plays)==np.array(cf_plays)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf = pd.read_csv(\"cf_data.csv\")\n",
    "sv = pd.read_csv(\"sv_data.csv\")\n",
    "\n",
    "\n",
    "cf = cf[cf[\"Player\"]==\"Pitcher\"]\n",
    "sv = sv[sv[\"Player\"]==\"Pitcher\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pitcher = cf[\"Pitcher\"].values.astype(int)\n",
    "statistic = sp.stats.itemfreq(pitcher) #.sort(axis = 0)\n",
    "\n",
    "number = np.array(frequ[:,1])\n",
    "\n",
    "for i in range(5):\n",
    "    maxi = np.argmax(number)\n",
    "    a = frequ[maxi]\n",
    "    number[maxi]=0\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split = cf[cf[\"Runner on 1st\"]!=None]\n",
    "print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ninawiedemann/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2821: DtypeWarning: Columns (253,254,255,256,257,258,259,289) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv eingelesen with length  13150\n",
      "Only Pitcher rows\n",
      "([527054.0, 285079.0, 592314.0, 448802.0, 656794.0], array([[  1.12526000e+05,   2.40000000e+02],\n",
      "       [  2.76351000e+05,   4.00000000e+00],\n",
      "       [  2.85079000e+05,   4.35000000e+02],\n",
      "       [  4.07793000e+05,   4.40000000e+01],\n",
      "       [  4.07822000e+05,   1.00000000e+01],\n",
      "       [  4.24144000e+05,   1.00000000e+01],\n",
      "       [  4.30661000e+05,   8.00000000e+00],\n",
      "       [  4.30912000e+05,   4.00000000e+01],\n",
      "       [  4.33217000e+05,   3.00000000e+00],\n",
      "       [  4.34442000e+05,   1.70000000e+01],\n",
      "       [  4.35400000e+05,   1.42000000e+02],\n",
      "       [  4.44468000e+05,   1.10000000e+01],\n",
      "       [  4.46399000e+05,   4.00000000e+00],\n",
      "       [  4.46899000e+05,   1.00000000e+01],\n",
      "       [  4.47714000e+05,   7.70000000e+01],\n",
      "       [  4.48609000e+05,   8.00000000e+00],\n",
      "       [  4.48614000e+05,   8.00000000e+00],\n",
      "       [  4.48802000e+05,   3.25000000e+02],\n",
      "       [  4.50212000e+05,   2.00000000e+00],\n",
      "       [  4.50308000e+05,   2.60000000e+01],\n",
      "       [  4.51584000e+05,   1.10000000e+01],\n",
      "       [  4.52657000e+05,   4.90000000e+01],\n",
      "       [  4.53265000e+05,   6.00000000e+00],\n",
      "       [  4.53281000e+05,   1.30000000e+01],\n",
      "       [  4.53286000e+05,   1.04000000e+02],\n",
      "       [  4.53343000e+05,   7.00000000e+00],\n",
      "       [  4.55009000e+05,   1.10000000e+01],\n",
      "       [  4.56501000e+05,   3.60000000e+01],\n",
      "       [  4.57768000e+05,   9.00000000e+00],\n",
      "       [  4.58006000e+05,   1.60000000e+01],\n",
      "       [  4.58681000e+05,   5.00000000e+01],\n",
      "       [  4.60283000e+05,   2.40000000e+01],\n",
      "       [  4.61829000e+05,   6.00000000e+01],\n",
      "       [  4.62382000e+05,   1.51000000e+02],\n",
      "       [  4.62515000e+05,   5.00000000e+00],\n",
      "       [  4.67008000e+05,   8.00000000e+00],\n",
      "       [  4.67100000e+05,   4.60000000e+01],\n",
      "       [  4.68504000e+05,   4.80000000e+01],\n",
      "       [  4.72610000e+05,   1.70000000e+01],\n",
      "       [  4.73879000e+05,   9.00000000e+00],\n",
      "       [  4.75479000e+05,   2.20000000e+01],\n",
      "       [  4.77569000e+05,   2.70000000e+01],\n",
      "       [  4.88748000e+05,   1.00000000e+01],\n",
      "       [  4.88846000e+05,   7.00000000e+00],\n",
      "       [  4.89334000e+05,   1.60000000e+01],\n",
      "       [  4.90063000e+05,   3.80000000e+01],\n",
      "       [  4.91646000e+05,   1.60000000e+01],\n",
      "       [  4.93157000e+05,   1.10000000e+01],\n",
      "       [  4.93200000e+05,   1.80000000e+01],\n",
      "       [  5.01697000e+05,   1.80000000e+01],\n",
      "       [  5.01789000e+05,   7.00000000e+00],\n",
      "       [  5.01925000e+05,   8.00000000e+00],\n",
      "       [  5.02004000e+05,   1.50000000e+01],\n",
      "       [  5.02046000e+05,   3.40000000e+01],\n",
      "       [  5.02179000e+05,   2.40000000e+01],\n",
      "       [  5.02188000e+05,   3.40000000e+01],\n",
      "       [  5.02190000e+05,   4.40000000e+01],\n",
      "       [  5.02239000e+05,   4.50000000e+01],\n",
      "       [  5.02748000e+05,   4.90000000e+01],\n",
      "       [  5.04379000e+05,   2.00000000e+00],\n",
      "       [  5.17414000e+05,   1.10000000e+01],\n",
      "       [  5.18567000e+05,   9.90000000e+01],\n",
      "       [  5.18693000e+05,   1.59000000e+02],\n",
      "       [  5.18715000e+05,   9.00000000e+00],\n",
      "       [  5.18748000e+05,   8.00000000e+00],\n",
      "       [  5.18774000e+05,   8.90000000e+01],\n",
      "       [  5.18875000e+05,   1.70000000e+01],\n",
      "       [  5.19008000e+05,   9.00000000e+00],\n",
      "       [  5.19043000e+05,   4.60000000e+01],\n",
      "       [  5.19076000e+05,   3.50000000e+01],\n",
      "       [  5.19166000e+05,   1.20000000e+01],\n",
      "       [  5.19294000e+05,   9.00000000e+00],\n",
      "       [  5.19301000e+05,   1.20000000e+01],\n",
      "       [  5.27054000e+05,   4.63000000e+02],\n",
      "       [  5.27055000e+05,   1.00000000e+02],\n",
      "       [  5.34812000e+05,   6.00000000e+00],\n",
      "       [  5.42194000e+05,   3.00000000e+00],\n",
      "       [  5.42432000e+05,   1.41000000e+02],\n",
      "       [  5.43037000e+05,   3.90000000e+01],\n",
      "       [  5.43118000e+05,   1.20000000e+01],\n",
      "       [  5.43272000e+05,   1.00000000e+00],\n",
      "       [  5.43339000e+05,   1.10000000e+01],\n",
      "       [  5.43506000e+05,   9.00000000e+00],\n",
      "       [  5.43557000e+05,   4.40000000e+01],\n",
      "       [  5.43652000e+05,   5.00000000e+00],\n",
      "       [  5.43779000e+05,   1.80000000e+01],\n",
      "       [  5.44727000e+05,   9.00000000e+00],\n",
      "       [  5.44836000e+05,   1.20000000e+01],\n",
      "       [  5.44931000e+05,   5.70000000e+01],\n",
      "       [  5.45332000e+05,   9.00000000e+00],\n",
      "       [  5.45346000e+05,   1.10000000e+01],\n",
      "       [  5.53878000e+05,   1.50000000e+01],\n",
      "       [  5.70257000e+05,   1.30000000e+01],\n",
      "       [  5.70632000e+05,   4.30000000e+01],\n",
      "       [  5.70663000e+05,   5.00000000e+00],\n",
      "       [  5.71521000e+05,   2.70000000e+01],\n",
      "       [  5.71578000e+05,   3.30000000e+01],\n",
      "       [  5.71871000e+05,   1.42000000e+02],\n",
      "       [  5.71882000e+05,   1.20000000e+01],\n",
      "       [  5.71901000e+05,   2.00000000e+00],\n",
      "       [  5.71927000e+05,   4.60000000e+01],\n",
      "       [  5.72096000e+05,   1.20000000e+01],\n",
      "       [  5.72193000e+05,   5.00000000e+00],\n",
      "       [  5.72208000e+05,   6.00000000e+00],\n",
      "       [  5.72831000e+05,   1.20000000e+01],\n",
      "       [  5.73109000e+05,   9.00000000e+00],\n",
      "       [  5.73185000e+05,   3.70000000e+01],\n",
      "       [  5.73186000e+05,   5.10000000e+01],\n",
      "       [  5.91693000e+05,   1.40000000e+01],\n",
      "       [  5.92127000e+05,   1.20000000e+01],\n",
      "       [  5.92130000e+05,   4.00000000e+00],\n",
      "       [  5.92314000e+05,   4.23000000e+02],\n",
      "       [  5.92422000e+05,   2.80000000e+01],\n",
      "       [  5.92426000e+05,   1.19000000e+02],\n",
      "       [  5.92570000e+05,   1.80000000e+01],\n",
      "       [  5.92612000e+05,   7.00000000e+00],\n",
      "       [  5.92665000e+05,   3.50000000e+01],\n",
      "       [  5.92815000e+05,   1.20000000e+01],\n",
      "       [  5.92836000e+05,   1.90000000e+01],\n",
      "       [  5.92866000e+05,   3.70000000e+01],\n",
      "       [  5.93140000e+05,   1.10000000e+01],\n",
      "       [  5.93576000e+05,   4.00000000e+00],\n",
      "       [  5.94798000e+05,   5.60000000e+01],\n",
      "       [  5.94840000e+05,   3.00000000e+00],\n",
      "       [  5.94902000e+05,   3.00000000e+01],\n",
      "       [  5.95014000e+05,   1.70000000e+01],\n",
      "       [  5.95191000e+05,   2.90000000e+01],\n",
      "       [  6.01713000e+05,   4.60000000e+01],\n",
      "       [  6.05151000e+05,   1.10000000e+01],\n",
      "       [  6.05177000e+05,   1.10000000e+01],\n",
      "       [  6.05195000e+05,   1.10000000e+01],\n",
      "       [  6.05200000e+05,   5.80000000e+01],\n",
      "       [  6.05218000e+05,   1.10000000e+01],\n",
      "       [  6.05388000e+05,   1.60000000e+01],\n",
      "       [  6.05397000e+05,   3.00000000e+01],\n",
      "       [  6.05400000e+05,   4.20000000e+01],\n",
      "       [  6.05452000e+05,   4.70000000e+01],\n",
      "       [  6.05538000e+05,   1.13000000e+02],\n",
      "       [  6.06424000e+05,   4.00000000e+00],\n",
      "       [  6.06965000e+05,   1.10000000e+01],\n",
      "       [  6.06983000e+05,   5.00000000e+00],\n",
      "       [  6.07192000e+05,   4.00000000e+01],\n",
      "       [  6.07229000e+05,   1.38000000e+02],\n",
      "       [  6.07352000e+05,   3.10000000e+01],\n",
      "       [  6.07457000e+05,   9.00000000e+00],\n",
      "       [  6.07625000e+05,   4.20000000e+01],\n",
      "       [  6.08379000e+05,   4.20000000e+01],\n",
      "       [  6.08678000e+05,   1.40000000e+01],\n",
      "       [  6.08716000e+05,   9.00000000e+00],\n",
      "       [  6.08718000e+05,   2.10000000e+01],\n",
      "       [  6.21199000e+05,   6.00000000e+00],\n",
      "       [  6.21295000e+05,   5.00000000e+00],\n",
      "       [  6.22766000e+05,   1.40000000e+01],\n",
      "       [  6.23149000e+05,   2.10000000e+01],\n",
      "       [  6.23352000e+05,   9.00000000e+00],\n",
      "       [  6.24586000e+05,   4.00000000e+00],\n",
      "       [  6.43327000e+05,   3.60000000e+01],\n",
      "       [  6.56794000e+05,   2.57000000e+02],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00],\n",
      "       [             nan,   1.00000000e+00]]))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from data_preprocess import Preprocessor\n",
    "\n",
    "#pre_cf = Preprocessor(\"cf_data.csv\",60)\n",
    "#new_data = pre_cf.concat_with_second(\"sv_data.csv\")\n",
    "#print(new_data)\n",
    "\n",
    "PATH = \"cf_data.csv\"\n",
    "LABELS = \"Pitch Type\"\n",
    "\n",
    "prepro = Preprocessor(PATH)\n",
    "players = prepro.get_list_with_most(\"Pitcher\")\n",
    "print(players)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Fastball (4-seam)', 'Slider', 'Fastball (2-seam)', 'Curveball', 'Changeup'],\n",
       " array([['Changeup', 29],\n",
       "        ['Curveball', 39],\n",
       "        ['Fastball (2-seam)', 82],\n",
       "        ['Fastball (4-seam)', 226],\n",
       "        ['Slider', 87]], dtype=object))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepro.cut_file_to_pitcher(527054.0)\n",
    "prepro.get_list_with_most(\"Pitch Type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cf.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# histogram of 5 players with most pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_preprocess import Preprocessor\n",
    "prepro = Preprocessor(\"cf_data.csv\")\n",
    "players, _ = prepro.get_list_with_most(\"Pitcher\")\n",
    "#print(players[2])\n",
    "pitchi = []\n",
    "for i in range(5):\n",
    "    prepro = Preprocessor(\"cf_data.csv\")\n",
    "    prepro.cut_file_to_pitcher(players[i])\n",
    "    _, stat = prepro.get_list_with_most(\"Pitch Type\")\n",
    "    pitchi.append(stat)\n",
    "print(pitchi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(players[i], \": \", np.sum(pitchi[i][:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data=np.random.random((4,10))\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "titles = players\n",
    "for i in range(5):\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.ylim([0,350])\n",
    "    y_pos = range(len(pitchi[i]))\n",
    "    plt.bar(y_pos, pitchi[i][:,1], align='center', alpha=0.5, width = 1)\n",
    "    #plt.ylim([0,350])\n",
    "    plt.xticks(y_pos, pitchi[i][:,0])\n",
    "    plt.ylabel('number of videos')\n",
    "    plt.title(titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(\"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to plot coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from data_preprocess import Preprocessor\n",
    "prepro = Preprocessor(\"cf_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players, _ = prepro.get_list_with_most(\"Pitcher\")\n",
    "prepro.select_movement(\"Stretch\")\n",
    "prepro.cut_file_to_pitcher(players[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = prepro.cf\n",
    "pitchi, _ = prepro.get_list_with_most(\"Pitch Type\")\n",
    "df = df[df[\"Pitch Type\"]==pitchi[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prepro.cf = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = prepro.get_coord_arr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "#z=range(167)\n",
    "for i in range(167):\n",
    "    ax.scatter(data[10, i, :16, 0], data[10, i, :16, 1], i, c= 'red', s=4)\n",
    "\n",
    "\n",
    "#for i in range(18):\n",
    "#    ax.scatter(data[10, :, i, 0], data[10, i, :, 1], z, c= 'red', s=1)\n",
    "    \n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "plt.show()\n",
    "#Axes3D.scatter(mean_data[0], mean_data[1], mean_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(max(prepro.cf['first_movement_frame_index'].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cf = pd.read_csv(\"cf_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model for one player (here: the one with most trials) and all his pitch types (Stretch&windup mixed):\n",
    "\n",
    "Convolutional NN with 4 conv layers and 3 fully connected feed forward layers, using regularization (L2 loss for weights and Dropout)\n",
    "\n",
    "Frames aligned by first_movement_frame, head coordinates removed (only first 12)\n",
    "\n",
    "nr classes 5 Batchsize 20 trained for 40 epochs, 100 balanced batches per epoch\n",
    "\n",
    "classes:  ['Changeup', 'Curveball', 'Fastball (2-seam)', 'Fastball (4-seam)', 'Slider']\n",
    "\n",
    "data shape: (463, 92, 12, 2) label_shape (463, 5) (463,)\n",
    "\n",
    "Test set size:  47  train set size:  416\n",
    "\n",
    "Shapes of train_x (416, 92, 12, 2) shape of test_x (47, 92, 12, 2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Accuracy test:  0.489361702128\n",
    "Accuracy train:  0.560096153846\n",
    "Loss test 2.0455\n",
    "Accuracy test:  0.531914893617\n",
    "Accuracy train:  0.5625\n",
    "Loss test 2.06014\n",
    "Accuracy test:  0.553191489362\n",
    "Accuracy train:  0.557692307692\n",
    "Loss test 2.04858\n",
    "Accuracy test:  0.489361702128\n",
    "Accuracy train:  0.572115384615\n",
    "Loss test 2.05759\n",
    "Accuracy test:  0.489361702128\n",
    "Accuracy train:  0.591346153846\n",
    "Loss test 2.04937\n",
    "Accuracy test:  0.531914893617\n",
    "Accuracy train:  0.603365384615\n",
    "Loss test 2.08457\n",
    "Accuracy test:  0.553191489362\n",
    "Accuracy train:  0.600961538462\n",
    "Loss test 2.07272\n",
    "Accuracy test:  0.531914893617\n",
    "Accuracy train:  0.622596153846\n",
    "Loss test 2.05784\n",
    "Accuracy test:  0.531914893617\n",
    "Accuracy train:  0.639423076923\n",
    "Loss test 1.99224\n",
    "Accuracy test:  0.574468085106\n",
    "Accuracy train:  0.620192307692\n",
    "True                   Test             ['Changeup', 'Curveball', 'Fastball (2-seam)', 'Fastball (4-seam)', 'Slider']\n",
    "Fastball (4-seam)    Fastball (4-seam)    ['0.00        ', '0.00        ', '0.00        ', '0.50        ', '0.49        ']\n",
    "Fastball (4-seam)    Fastball (4-seam)    ['0.00        ', '0.01        ', '0.01        ', '0.61        ', '0.37        ']\n",
    "Fastball (4-seam)    Slider               ['0.00        ', '0.00        ', '0.00        ', '0.29        ', '0.71        ']\n",
    "Slider               Fastball (2-seam)    ['0.02        ', '0.12        ', '0.40        ', '0.19        ', '0.27        ']\n",
    "Changeup             Fastball (2-seam)    ['0.15        ', '0.23        ', '0.44        ', '0.08        ', '0.09        ']\n",
    "Fastball (4-seam)    Fastball (2-seam)    ['0.14        ', '0.18        ', '0.26        ', '0.17        ', '0.25        ']\n",
    "Fastball (2-seam)    Fastball (2-seam)    ['0.22        ', '0.25        ', '0.29        ', '0.11        ', '0.11        ']\n",
    "Fastball (4-seam)    Fastball (2-seam)    ['0.32        ', '0.09        ', '0.36        ', '0.11        ', '0.12        ']\n",
    "Fastball (4-seam)    Fastball (4-seam)    ['0.00        ', '0.00        ', '0.00        ', '0.87        ', '0.13        ']\n",
    "Slider               Slider               ['0.07        ', '0.17        ', '0.25        ', '0.19        ', '0.32        ']\n",
    "Fastball (4-seam)    Fastball (4-seam)    ['0.00        ', '0.02        ', '0.01        ', '0.89        ', '0.08        ']\n",
    "Slider               Changeup             ['0.32        ', '0.12        ', '0.32        ', '0.10        ', '0.15        ']\n",
    "Slider               Slider               ['0.00        ', '0.01        ', '0.01        ', '0.44        ', '0.55        ']\n",
    "Fastball (4-seam)    Fastball (4-seam)    ['0.00        ', '0.01        ', '0.00        ', '0.81        ', '0.18        ']\n",
    "Fastball (4-seam)    Fastball (4-seam)    ['0.00        ', '0.01        ', '0.01        ', '0.62        ', '0.36        ']\n",
    "Fastball (4-seam)    Slider               ['0.00        ', '0.01        ', '0.00        ', '0.29        ', '0.70        ']\n",
    "Fastball (4-seam)    Fastball (4-seam)    ['0.00        ', '0.00        ', '0.00        ', '0.91        ', '0.09        ']\n",
    "Fastball (4-seam)    Fastball (4-seam)    ['0.00        ', '0.00        ', '0.00        ', '0.74        ', '0.26        ']\n",
    "Fastball (4-seam)    Slider               ['0.09        ', '0.17        ', '0.22        ', '0.18        ', '0.33        ']\n",
    "Fastball (4-seam)    Fastball (4-seam)    ['0.00        ', '0.09        ', '0.00        ', '0.88        ', '0.03        ']\n",
    "Fastball (4-seam)    Fastball (4-seam)    ['0.00        ', '0.00        ', '0.00        ', '0.93        ', '0.07        ']\n",
    "Fastball (4-seam)    Changeup             ['0.68        ', '0.02        ', '0.27        ', '0.02        ', '0.01        ']\n",
    "Curveball            Curveball            ['0.00        ', '0.87        ', '0.01        ', '0.03        ', '0.09        ']\n",
    "Fastball (4-seam)    Fastball (4-seam)    ['0.00        ', '0.00        ', '0.00        ', '0.89        ', '0.10        ']\n",
    "Fastball (2-seam)    Fastball (2-seam)    ['0.33        ', '0.08        ', '0.45        ', '0.06        ', '0.08        ']\n",
    "Fastball (4-seam)    Fastball (2-seam)    ['0.04        ', '0.17        ', '0.33        ', '0.18        ', '0.28        ']\n",
    "Fastball (4-seam)    Slider               ['0.12        ', '0.17        ', '0.24        ', '0.17        ', '0.30        ']\n",
    "Fastball (4-seam)    Fastball (4-seam)    ['0.00        ', '0.00        ', '0.00        ', '0.65        ', '0.34        ']\n",
    "Fastball (4-seam)    Curveball            ['0.03        ', '0.59        ', '0.15        ', '0.10        ', '0.12        ']\n",
    "Changeup             Fastball (2-seam)    ['0.03        ', '0.09        ', '0.53        ', '0.09        ', '0.27        ']\n",
    "Curveball            Curveball            ['0.05        ', '0.80        ', '0.10        ', '0.03        ', '0.02        ']\n",
    "Changeup             Slider               ['0.00        ', '0.32        ', '0.13        ', '0.20        ', '0.34        ']\n",
    "Curveball            Curveball            ['0.00        ', '0.96        ', '0.00        ', '0.01        ', '0.03        ']\n",
    "Slider               Fastball (4-seam)    ['0.00        ', '0.02        ', '0.01        ', '0.57        ', '0.40        ']\n",
    "Fastball (2-seam)    Changeup             ['0.69        ', '0.03        ', '0.21        ', '0.04        ', '0.03        ']\n",
    "Slider               Slider               ['0.00        ', '0.00        ', '0.00        ', '0.44        ', '0.56        ']\n",
    "Fastball (4-seam)    Fastball (4-seam)    ['0.00        ', '0.16        ', '0.03        ', '0.42        ', '0.39        ']\n",
    "Fastball (2-seam)    Fastball (2-seam)    ['0.18        ', '0.21        ', '0.27        ', '0.15        ', '0.19        ']\n",
    "Fastball (4-seam)    Slider               ['0.00        ', '0.02        ', '0.08        ', '0.40        ', '0.50        ']\n",
    "Fastball (4-seam)    Fastball (4-seam)    ['0.00        ', '0.00        ', '0.00        ', '0.80        ', '0.20        ']\n",
    "Fastball (2-seam)    Changeup             ['0.91        ', '0.00        ', '0.09        ', '0.00        ', '0.00        ']\n",
    "Fastball (4-seam)    Fastball (4-seam)    ['0.00        ', '0.00        ', '0.00        ', '0.77        ', '0.22        ']\n",
    "Slider               Slider               ['0.09        ', '0.17        ', '0.22        ', '0.18        ', '0.33        ']\n",
    "Slider               Fastball (4-seam)    ['0.00        ', '0.01        ', '0.00        ', '0.68        ', '0.31        ']\n",
    "Slider               Slider               ['0.09        ', '0.17        ', '0.22        ', '0.18        ', '0.33        ']\n",
    "Fastball (4-seam)    Slider               ['0.09        ', '0.17        ', '0.22        ', '0.18        ', '0.33        ']\n",
    "Fastball (4-seam)    Fastball (4-seam)    ['0.00        ', '0.00        ', '0.00        ', '0.67        ', '0.33        ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shorter version of conv net\n",
    "\n",
    "all with alignment and concatenated data\n",
    "\n",
    "conv_short version,      mit max_pooling, with conv-batch_norm-dropout architecture\n",
    "    \n",
    "player0: 53% (5 classes), 46,                  35\n",
    "\n",
    "player1: 80% (2 classes), 85,                  70\n",
    "\n",
    "player2: 27% (6 classes), 21,                  35\n",
    "\n",
    "player3: 45% (5 classes), 23,                  36\n",
    "\n",
    "player4: 35% (4 classes), 52,                  46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same but only one pitchtype:\n",
    "\n",
    "and concat data and alignment with conv-batch_norm-dropout architecture\n",
    "\n",
    "player0: 62\n",
    "\n",
    "player1: 77\n",
    "\n",
    "player2: 75\n",
    "\n",
    "player3: 59\n",
    "\n",
    "player4: 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trained on concatenated data from cf and sv (4 coordinates) on only Windup 53%, only Stretch 54%, all 50%\n",
    "(without alignment and without regularization loss)\n",
    "\"\"\"\n",
    "def best_in_cluster_concat53(self, x, nr_classes, training, rate_dropout=0.6, act=tf.nn.relu):\n",
    "        shape = x.get_shape().as_list()\n",
    "        x_ = tf.reshape(x, (-1, shape[1], shape[2]*shape[3]))\n",
    "        net = tf.layers.conv1d(x_, filters=256, kernel_size=5, strides=2, activation=act, name=\"conv1\")\n",
    "        tf.summary.histogram(\"conv_1_layer\", net)\n",
    "        # net = tf.layers.dropout(net, rate=rate_dropout, training=training)\n",
    "        net = tf.layers.conv1d(net, filters=128, kernel_size=3, activation = act, name=\"conv4\")\n",
    "        shapes = net.get_shape().as_list()\n",
    "        ff = tf.reshape(net, (-1, shapes[1]*shapes[2]))\n",
    "        logits = tf.layers.dense(ff, nr_classes, activation = None, name = \"ff3\")\n",
    "        out = tf.nn.softmax(logits)\n",
    "        return out, logits\n",
    "    \n",
    "\"\"\"Trained on only one pitch type: about 75% with higher batchsize 78\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align pitches by \"first_movement_frame_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "release_frame = prepro.cf[\"first_movement_frame_index\"].values\n",
    "\n",
    "def align_frames(data, release_frame, fr_before, fr_after):\n",
    "    \"\"\"\n",
    "    Takes the data and an array that indicates the frame number of the first movement\n",
    "    cuts all data to fr_before the release_frame and fr_after the release frame\n",
    "    returns an array of size data.shape except the second dimension is cut to length fr_before+fr_after\n",
    "    \"\"\"\n",
    "    M, _, nr_joints, nr_coord = data.shape\n",
    "    new = np.zeros((M, fr_after+fr_before, nr_joints, nr_coord))\n",
    "    for i, row in enumerate(data):\n",
    "        ind = release_frame[i]\n",
    "        if pd.isnull(ind):\n",
    "            ind = np.mean(release_frame[:i])\n",
    "        start = int(ind-fr_before)\n",
    "        end = int(ind+ fr_after)\n",
    "        #print(start, end)\n",
    "        new[i] = data[i, start:end, :,:]\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN/ LSTM\n",
    "tf learn module to create a RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tflearn\n",
    "def get_network_wide(frames, input_size, num_classes):\n",
    "    \"\"\"Create a one-layer LSTM\"\"\"\n",
    "    net = tflearn.input_data(shape=[None, frames, input_size])\n",
    "    net = tflearn.lstm(net, 256, dropout=0.2)\n",
    "    net = tflearn.fully_connected(net, num_classes, activation='softmax')\n",
    "    net = tflearn.regression(net, optimizer='adam',\n",
    "                             loss='categorical_crossentropy', name='output1')\n",
    "    return net\n",
    "model = DNN(get_network_wide(N, nr_joints*nr_coordinates, nr_classes))\n",
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"first_movement_frame_index\")\n",
    "print(prepro.cf[\"first_movement_frame_index\"].values[:50])\n",
    "\n",
    "print(\"'pitch_frame_index'\")\n",
    "print(np.where(prepro.cf['pitch_frame_index'].values<0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on best script so far (54% on all data)\n",
    "\n",
    "regularization best weighted 0.0005\n",
    "\n",
    "dropout made it worse\n",
    "\n",
    "tan also up to 50, leaky relu same\n",
    "\n",
    "aligned made it worse\n",
    "\n",
    "only one conv layer: also 54% but overfitting\n",
    "\n",
    "TRAIN IT ON JUST HEAD COORDINATES: (13:18) 40%, ON JUST ONE COORDINATE(14): 30% --> something wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex = pd.read_csv(\"cf_data.csv\", converters = {'0': eval, '1': eval, '2': eval, '3': eval, '4': eval, '5': eval, '6': eval, '7': eval, '8': eval, '9': eval, '10': eval, '11': eval, '12': eval, '13': eval, '14': eval, '15': eval, '16': eval, '17': eval, '18': eval, '19': eval, '20': eval, '21': eval, '22': eval, '23': eval, '24': eval, '25': eval, '26': eval, '27': eval, '28': eval, '29': eval, '30': eval, '31': eval, '32': eval, '33': eval, '34': eval, '35': eval, '36': eval, '37': eval, '38': eval, '39': eval, '40': eval, '41': eval, '42': eval, '43': eval, '44': eval, '45': eval, '46': eval, '47': eval, '48': eval, '49': eval, '50': eval, '51': eval, '52': eval, '53': eval, '54': eval, '55': eval, '56': eval, '57': eval, '58': eval, '59': eval, '60': eval, '61': eval, '62': eval, '63': eval, '64': eval, '65': eval, '66': eval, '67': eval, '68': eval, '69': eval, '70': eval, '71': eval, '72': eval, '73': eval, '74': eval, '75': eval, '76': eval, '77': eval, '78': eval, '79': eval, '80': eval, '81': eval, '82': eval, '83': eval, '84': eval, '85': eval, '86': eval, '87': eval, '88': eval, '89': eval, '90': eval, '91': eval, '92': eval, '93': eval, '94': eval, '95': eval, '96': eval, '97': eval, '98': eval, '99': eval, '100': eval, '101': eval, '102': eval, '103': eval, '104': eval, '105': eval, '106': eval, '107': eval, '108': eval, '109': eval, '110': eval, '111': eval, '112': eval, '113': eval, '114': eval, '115': eval, '116': eval, '117': eval, '118': eval, '119': eval, '120': eval, '121': eval, '122': eval, '123': eval, '124': eval, '125': eval, '126': eval, '127': eval, '128': eval, '129': eval, '130': eval, '131': eval, '132': eval, '133': eval, '134': eval, '135': eval, '136': eval, '137': eval, '138': eval, '139': eval, '140': eval, '141': eval, '142': eval, '143': eval, '144': eval, '145': eval, '146': eval, '147': eval, '148': eval, '149': eval, '150': eval, '151': eval, '152': eval, '153': eval, '154': eval, '155': eval, '156': eval, '157': eval, '158': eval, '159': eval, '160': eval, '161': eval, '162': eval, '163': eval, '164': eval, '165': eval, '166': eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "for i in range(167):\n",
    "    sys.stdout.write(\"'\"+str(i)+\"': eval, \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df ={\"Batchsize\": 40., \"Epochs\": 50., \"batch_nr_in_epoch\": 100., \"file\": \"cf\", \"act\": tf.nn.relu,\n",
    "                   \"CUT_OFF_Classes\": 50., \"dropout\": 0.6, \"learning_rate\": 0.0001, \"lstm_units\": 4., \n",
    "                   \"lstm_hidden_layers\": 128.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df =pd.DataFrame({\"Batchsize\": pd.Series(40.), \"Epochs\": pd.Series(50.), \"batch_nr_in_epoch\": pd.Series(100.), \n",
    "                  \"file\": pd.Series(\"cf\"), \"act\": pd.Series(tf.nn.relu), \"nr_joints\": pd.Series(12),\n",
    "                   \"CUT_OFF_Classes\": pd.Series(50.), \"dropout\": pd.Series(0.6), \"learning_rate\": pd.Series(0.0001),\n",
    "                  \"lstm_units\": pd.Series(4.),\"lstm_hidden_layers\": pd.Series(128.), \"loss\": pd.Series([[5,4,3,2,1]]),\n",
    "                 \"test_acc\": pd.Series([[3,4,5,6]]), \"highest_acc\": pd.Series(10), \"nr_classes\": pd.Series(5), \"align\": pd.Series(True)\n",
    "                 , \"train_acc\": pd.Series([[3,4,5]]), \"len_train\": pd.Series(2000), \"model\":pd.Series(\"conv2d\")})\n",
    "df.to_csv(\"test_parameters.csv\")\n",
    "#{\"Batchsize\": 40., \"Epochs\": 50.}\n",
    "#df[\"Batchsize\"]=pd.Series(40)\n",
    "#df[\"Epoch\"]=10\n",
    "#a = pd.DataFrame.from_dict(df, orient = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new = pd.read_csv(\"test_parameters.csv\")\n",
    "columns = new.columns.values.tolist()\n",
    "print(len(columns))\n",
    "#add = pd.DataFrame([[0, 20,30 , 12, 60, tf.nn.tanh,[1,2,3], 0.4, \"sv\", 0.01, 256, 5]], columns=columns)\n",
    "#print(add)\n",
    "#concat = new.append(add, ignore_index = True)\n",
    "#print(new)\n",
    "#print(concat[\"coordinates_used\"])\n",
    "#cut = new.drop(new.columns[[0]], axis=1, inplace=True)\n",
    "#print(cut.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new = pd.read_csv(\"test_parameters.csv\")\n",
    "columns = new.columns.values.tolist()\n",
    "add = pd.DataFrame([[0, BATCHSIZE, CUT_OFF_Classes , EPOCHS, act, align, batch_nr_in_epoch, rate_dropout\n",
    "                     , PATH, max(acc_test), learning_rate, loss, n_hidden, nr_layers, nr_classes, nr_joints, test_acc, train_acc]], columns=columns)\n",
    "concat = new.append(add, ignore_index = True)\n",
    "concat.to_csv(\"new\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop one row of csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inde = pd.read_csv(\"test_parameters.csv\")\n",
    "a = inde.drop(inde.columns[[0]], axis=1, inplace=True)\n",
    "#print(a[\"Epochs\"])\n",
    "a.to_csv(\"test_parameters.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EPOCHS = 80\n",
    "batch_nr_in_epoch = 100\n",
    "align = False\n",
    "act = tf.nn.relu\n",
    "rate_dropout = 0\n",
    "learning_rate = 0.0005\n",
    "nr_layers = 4\n",
    "n_hidden = 128\n",
    "BATCHSIZE = 40\n",
    "network = \"conv1d (256, 5) - conv1d(128, 3) - dense(nr_classes) - softmax\"\n",
    "CUT_OFF_Classes = 50\n",
    "PATH = \"sv\"\n",
    "len_train = 5605\n",
    "losses= [6,5,4]\n",
    "nr_classes = 9\n",
    "nr_joints =12\n",
    "acc_train = [1,2,3]\n",
    "acc_test = [2,3,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new = pd.read_csv(\"test_parameters_testing.csv\")\n",
    "columns = new.columns.values.tolist()# .append(\"optimizer\")\n",
    "    # print(len(columns))\n",
    "    # print(\"Written to csv: \", BATCHSIZE, CUT_OFF_Classes , EPOCHS, act, align, batch_nr_in_epoch, rate_dropout\n",
    "    #                      , PATH, max(acc_test), learning_rate, len_train, losses, n_hidden, nr_layers, network, nr_classes,\n",
    "    #                      nr_joints, acc_train, acc_test)\n",
    "\n",
    "add = pd.DataFrame([[0, BATCHSIZE, CUT_OFF_Classes , EPOCHS, act, align, batch_nr_in_epoch, rate_dropout\n",
    "                     , PATH, max(acc_test), learning_rate, len_train, losses, n_hidden, nr_layers, network, nr_classes,\n",
    "                     nr_joints, acc_train, acc_test, \"sgd\", \"dhe\"]], columns=columns)\n",
    "concat = new.append(add, ignore_index = True)\n",
    "concat[\"optimizer\"]= \"sgd\"\n",
    "concat.drop(concat.columns[[0]], axis=1, inplace=True)\n",
    "concat.to_csv(\"test_parameters_testing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test_parameters.csv\")\n",
    "columns = df.columns.values.tolist()\n",
    "print(eval(columns))\n",
    "# df = df.drop(df.index[[0,1,2,3,4,5]])\n",
    "# df.drop(df.columns[[0,1,2,3]], axis=1, inplace=True)\n",
    "#df[\"1st_hidden_dense\"]= pd.Series(1024)\n",
    "#df[\"1st_hidden_dense\"]= 1024\n",
    "#df[\"2nd_hidden_dense\"]= pd.Series(128)\n",
    "#df[\"2nd_hidden_dense\"]= 128\n",
    "#df.drop(df.columns[[0]], axis=1, inplace=True)\n",
    "#df.to_csv(\"test_parameters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv = pd.read_csv(\"beispiel.csv\")\n",
    "cf = pd.read_csv(\"cf_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf = pd.read_csv(\"cf_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.stats\n",
    "test = cf[\"Game\"].values\n",
    "#print(np.unique(test))\n",
    "print(max(sp.stats.itemfreq(test)[:, 1]))\n",
    "#print(cf.iloc[3086], cf.iloc[9464])\n",
    "#print(len(cf))\n",
    "#print(len(cf.iloc[3086].values))\n",
    "eins = cf.iloc[3086].values\n",
    "zwei = cf.iloc[9464].values\n",
    "print(test[3086], test[9464])\n",
    "for i in range(len(eins)):\n",
    "    if eins[i]!=zwei[i]:\n",
    "        print(cf.columns.tolist()[i], eins[i], zwei[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "directory = \"/Users/ninawiedemann/Desktop/UNI/Praktikum/output/\"\n",
    "list_files = listdir(directory)\n",
    "start_frames = cf.columns.get_loc(\"0\")\n",
    "#print(list_files)\n",
    "for file in list_files:\n",
    "    if file[0]!='.':\n",
    "        csv = pd.read_csv(directory+file)\n",
    "        #print(csv[\"Unnamed: 0\"].values)\n",
    "        game_id = csv[csv[\"Frame\"]==\"Game\"][\"Pitcher_player\"].values[0]\n",
    "        last_frame = eval(csv[csv[\"Frame\"]==\"# of last frame\"][\"Pitcher_player\"].values[0])+1\n",
    "        print(game_id, last_frame)\n",
    "        #ind = cf[cf[\"play_id\"]==game_id].index.values\n",
    "        #print(ind)\n",
    "\n",
    "        #print(cf[\"play_id\"].values)\n",
    "        #print(cf.columns.tolist())\n",
    "        \n",
    "        location_play = cf[cf[\"Game\"]==game_id].index.values\n",
    "        print(location_play)\n",
    "        if len(location_play)==4:\n",
    "            cf.drop(cf.index[[location_play[2], location_play[3]]])\n",
    "        # get index of play_id in cf\n",
    "        for i in range(last_frame):\n",
    "            pitcher_arr = csv[\"Pitcher_player\"].values[i].replace('\\n', ',').replace('[  ', '[').replace(\"  \", \",\").replace(\",,\",\",\")\n",
    "            batter_arr = csv[\"Batter_player\"].values[i].replace('\\n', ',').replace('[  ', '[').replace(\"  \", \",\").replace(\",,\",\",\")\n",
    "            \n",
    "            cf.iloc[int(location_play[0]), start_frames+i] = pitcher_arr #csv[\"Pitcher_player\"].values[i]\n",
    "            cf.iloc[int(location_play[1]), start_frames+i] = batter_arr #csv[\"Batter_player\"].values[i]\n",
    "            # check if right order of pitcher and batter\n",
    "\n",
    "cf.to_csv(\"unprocessed_data.csv\")\n",
    "\n",
    "print(len(cf.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unpro = pd.read_csv(\"unprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = unpro[unpro[\"Game\"]==\"490780-7be4d62a-6ddb-41e2-9331-dd9656df1819\"] #.index.values\n",
    "#print(lines)\n",
    "bsp  = lines[\"162\"].values[1]\n",
    "# print(repr(bsp))\n",
    "#besp = bsp.replace('\\n', ',').replace('[  ', '[').replace(\"  \", \",\").replace(\",,\",\",\")\n",
    "#print(besp)\n",
    "#import ast\n",
    "print(eval(bsp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cf_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = df[df[\"Game\"]==\"490780-7be4d62a-6ddb-41e2-9331-dd9656df1819\"]\n",
    "bsp1 = lines[\"162\"].values[1]\n",
    "print(bsp1)\n",
    "print(eval(bsp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = unpro[\"Game\"].values\n",
    "#print(np.unique(test))\n",
    "print(max(sp.stats.itemfreq(test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_preprocess import Preprocessor\n",
    "pre = Preprocessor(\"unprocessed_data.csv\")\n",
    "pre.remove_small_classes(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303.0 0.0\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"unpro_all_coord.npy\")\n",
    "print(np.amax(data), np.amin(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6422, 167, 18, 2)\n",
      "411 0 5\n",
      "411 1 5\n",
      "414 0 5\n",
      "417 0 5\n",
      "417 1 5\n",
      "419 0 5\n",
      "419 1 5\n",
      "441 98 0\n",
      "441 98 1\n",
      "441 98 2\n",
      "441 98 3\n",
      "441 98 4\n",
      "441 98 5\n",
      "441 98 6\n",
      "441 98 7\n",
      "441 98 8\n",
      "441 98 9\n",
      "441 98 10\n",
      "441 98 11\n",
      "441 102 0\n",
      "441 102 1\n",
      "441 102 2\n",
      "441 102 3\n",
      "441 102 4\n",
      "441 102 5\n",
      "441 102 6\n",
      "441 102 7\n",
      "441 102 8\n",
      "441 102 9\n",
      "441 102 10\n",
      "441 102 11\n",
      "441 106 0\n",
      "441 106 1\n",
      "441 106 2\n",
      "441 106 3\n",
      "441 106 4\n",
      "441 106 5\n",
      "441 106 6\n",
      "441 106 7\n",
      "441 106 8\n",
      "441 106 9\n",
      "441 106 10\n",
      "441 106 11\n",
      "443 0 1\n",
      "443 0 4\n",
      "443 0 5\n",
      "443 99 0\n",
      "443 99 1\n",
      "443 99 2\n",
      "443 99 3\n",
      "443 99 4\n",
      "443 99 5\n",
      "443 99 6\n",
      "443 99 7\n",
      "443 99 8\n",
      "443 99 9\n",
      "443 99 10\n",
      "443 99 11\n",
      "453 0 5\n",
      "453 1 5\n",
      "460 0 5\n",
      "460 1 5\n",
      "465 102 0\n",
      "465 102 1\n",
      "465 102 2\n",
      "465 102 3\n",
      "465 102 4\n",
      "465 102 5\n",
      "465 102 6\n",
      "465 102 7\n",
      "465 102 8\n",
      "465 102 9\n",
      "465 102 10\n",
      "465 102 11\n",
      "467 0 5\n",
      "467 1 5\n",
      "468 0 5\n",
      "477 0 5\n",
      "481 97 0\n",
      "481 97 1\n",
      "481 97 2\n",
      "481 97 3\n",
      "481 97 4\n",
      "481 97 5\n",
      "481 97 6\n",
      "481 97 7\n",
      "481 97 8\n",
      "481 97 9\n",
      "481 97 10\n",
      "481 97 11\n",
      "484 97 0\n",
      "484 97 1\n",
      "484 97 2\n",
      "484 97 3\n",
      "484 97 4\n",
      "484 97 5\n",
      "484 97 6\n",
      "484 97 7\n",
      "484 97 8\n",
      "484 97 9\n",
      "484 97 10\n",
      "484 97 11\n",
      "485 107 0\n",
      "485 107 1\n",
      "485 107 2\n",
      "485 107 3\n",
      "485 107 4\n",
      "485 107 5\n",
      "485 107 6\n",
      "485 107 7\n",
      "485 107 8\n",
      "485 107 9\n",
      "485 107 10\n",
      "485 107 11\n",
      "497 0 5\n",
      "497 1 5\n",
      "497 104 0\n",
      "497 104 1\n",
      "497 104 2\n",
      "497 104 3\n",
      "497 104 4\n",
      "497 104 5\n",
      "497 104 6\n",
      "497 104 7\n",
      "497 104 8\n",
      "497 104 9\n",
      "497 104 10\n",
      "497 104 11\n",
      "500 97 0\n",
      "500 97 1\n",
      "500 97 2\n",
      "500 97 3\n",
      "500 97 4\n",
      "500 97 5\n",
      "500 97 6\n",
      "500 97 7\n",
      "500 97 8\n",
      "500 97 9\n",
      "500 97 10\n",
      "500 97 11\n",
      "501 97 0\n",
      "501 97 1\n",
      "501 97 2\n",
      "501 97 3\n",
      "501 97 4\n",
      "501 97 5\n",
      "501 97 6\n",
      "501 97 7\n",
      "501 97 8\n",
      "501 97 9\n",
      "501 97 10\n",
      "501 97 11\n",
      "503 0 5\n",
      "503 96 0\n",
      "503 96 1\n",
      "503 96 2\n",
      "503 96 3\n",
      "503 96 4\n",
      "503 96 5\n",
      "503 96 6\n",
      "503 96 7\n",
      "503 96 8\n",
      "503 96 9\n",
      "503 96 10\n",
      "503 96 11\n",
      "503 100 0\n",
      "503 100 1\n",
      "503 100 2\n",
      "503 100 3\n",
      "503 100 4\n",
      "503 100 5\n",
      "503 100 6\n",
      "503 100 7\n",
      "503 100 8\n",
      "503 100 9\n",
      "503 100 10\n",
      "503 100 11\n",
      "504 97 0\n",
      "504 97 1\n",
      "504 97 2\n",
      "504 97 3\n",
      "504 97 4\n",
      "504 97 5\n",
      "504 97 6\n",
      "504 97 7\n",
      "504 97 8\n",
      "504 97 9\n",
      "504 97 10\n",
      "504 97 11\n",
      "507 0 3\n",
      "507 1 3\n",
      "508 99 0\n",
      "508 99 1\n",
      "508 99 2\n",
      "508 99 3\n",
      "508 99 4\n",
      "508 99 5\n",
      "508 99 6\n",
      "508 99 7\n",
      "508 99 8\n",
      "508 99 9\n",
      "508 99 10\n",
      "508 99 11\n",
      "511 95 0\n",
      "511 95 1\n",
      "511 95 2\n",
      "511 95 3\n",
      "511 95 4\n",
      "511 95 5\n",
      "511 95 6\n",
      "511 95 7\n",
      "511 95 8\n",
      "511 95 9\n",
      "511 95 10\n",
      "511 95 11\n",
      "513 96 0\n",
      "513 96 1\n",
      "513 96 2\n",
      "513 96 3\n",
      "513 96 4\n",
      "513 96 5\n",
      "513 96 6\n",
      "513 96 7\n",
      "513 96 8\n",
      "513 96 9\n",
      "513 96 10\n",
      "513 96 11\n",
      "513 98 0\n",
      "513 98 1\n",
      "513 98 2\n",
      "513 98 3\n",
      "513 98 4\n",
      "513 98 5\n",
      "513 98 6\n",
      "513 98 7\n",
      "513 98 8\n",
      "513 98 9\n",
      "513 98 10\n",
      "513 98 11\n",
      "514 96 0\n",
      "514 96 1\n",
      "514 96 2\n",
      "514 96 3\n",
      "514 96 4\n",
      "514 96 5\n",
      "514 96 6\n",
      "514 96 7\n",
      "514 96 8\n",
      "514 96 9\n",
      "514 96 10\n",
      "514 96 11\n",
      "516 97 0\n",
      "516 97 1\n",
      "516 97 2\n",
      "516 97 3\n",
      "516 97 4\n",
      "516 97 5\n",
      "516 97 6\n",
      "516 97 7\n",
      "516 97 8\n",
      "516 97 9\n",
      "516 97 10\n",
      "516 97 11\n",
      "516 99 0\n",
      "516 99 1\n",
      "516 99 2\n",
      "516 99 3\n",
      "516 99 4\n",
      "516 99 5\n",
      "516 99 6\n",
      "516 99 7\n",
      "516 99 8\n",
      "516 99 9\n",
      "516 99 10\n",
      "516 99 11\n",
      "517 96 0\n",
      "517 96 1\n",
      "517 96 2\n",
      "517 96 3\n",
      "517 96 4\n",
      "517 96 5\n",
      "517 96 6\n",
      "517 96 7\n",
      "517 96 8\n",
      "517 96 9\n",
      "517 96 10\n",
      "517 96 11\n",
      "522 90 0\n",
      "522 90 1\n",
      "522 90 2\n",
      "522 90 3\n",
      "522 90 4\n",
      "522 90 5\n",
      "522 90 6\n",
      "522 90 7\n",
      "522 90 8\n",
      "522 90 9\n",
      "522 90 10\n",
      "522 90 11\n",
      "524 100 0\n",
      "524 100 1\n",
      "524 100 2\n",
      "524 100 3\n",
      "524 100 4\n",
      "524 100 5\n",
      "524 100 6\n",
      "524 100 7\n",
      "524 100 8\n",
      "524 100 9\n",
      "524 100 10\n",
      "524 100 11\n",
      "527 100 0\n",
      "527 100 1\n",
      "527 100 2\n",
      "527 100 3\n",
      "527 100 4\n",
      "527 100 5\n",
      "527 100 6\n",
      "527 100 7\n",
      "527 100 8\n",
      "527 100 9\n",
      "527 100 10\n",
      "527 100 11\n",
      "527 103 0\n",
      "527 103 1\n",
      "527 103 2\n",
      "527 103 3\n",
      "527 103 4\n",
      "527 103 5\n",
      "527 103 6\n",
      "527 103 7\n",
      "527 103 8\n",
      "527 103 9\n",
      "527 103 10\n",
      "527 103 11\n",
      "528 102 0\n",
      "528 102 1\n",
      "528 102 2\n",
      "528 102 3\n",
      "528 102 4\n",
      "528 102 5\n",
      "528 102 6\n",
      "528 102 7\n",
      "528 102 8\n",
      "528 102 9\n",
      "528 102 10\n",
      "528 102 11\n",
      "528 107 0\n",
      "528 107 1\n",
      "528 107 2\n",
      "528 107 3\n",
      "528 107 4\n",
      "528 107 5\n",
      "528 107 6\n",
      "528 107 7\n",
      "528 107 8\n",
      "528 107 9\n",
      "528 107 10\n",
      "528 107 11\n",
      "530 100 0\n",
      "530 100 1\n",
      "530 100 2\n",
      "530 100 3\n",
      "530 100 4\n",
      "530 100 5\n",
      "530 100 6\n",
      "530 100 7\n",
      "530 100 8\n",
      "530 100 9\n",
      "530 100 10\n",
      "530 100 11\n",
      "531 100 0\n",
      "531 100 1\n",
      "531 100 2\n",
      "531 100 3\n",
      "531 100 4\n",
      "531 100 5\n",
      "531 100 6\n",
      "531 100 7\n",
      "531 100 8\n",
      "531 100 9\n",
      "531 100 10\n",
      "531 100 11\n",
      "533 89 0\n",
      "533 89 1\n",
      "533 89 2\n",
      "533 89 3\n",
      "533 89 4\n",
      "533 89 5\n",
      "533 89 6\n",
      "533 89 7\n",
      "533 89 8\n",
      "533 89 9\n",
      "533 89 10\n",
      "533 89 11\n",
      "534 97 0\n",
      "534 97 1\n",
      "534 97 2\n",
      "534 97 3\n",
      "534 97 4\n",
      "534 97 5\n",
      "534 97 6\n",
      "534 97 7\n",
      "534 97 8\n",
      "534 97 9\n",
      "534 97 10\n",
      "534 97 11\n",
      "535 88 0\n",
      "535 88 1\n",
      "535 88 2\n",
      "535 88 3\n",
      "535 88 4\n",
      "535 88 5\n",
      "535 88 6\n",
      "535 88 7\n",
      "535 88 8\n",
      "535 88 9\n",
      "535 88 10\n",
      "535 88 11\n",
      "535 94 0\n",
      "535 94 1\n",
      "535 94 2\n",
      "535 94 3\n",
      "535 94 4\n",
      "535 94 5\n",
      "535 94 6\n",
      "535 94 7\n",
      "535 94 8\n",
      "535 94 9\n",
      "535 94 10\n",
      "535 94 11\n",
      "535 97 0\n",
      "535 97 1\n",
      "535 97 2\n",
      "535 97 3\n",
      "535 97 4\n",
      "535 97 5\n",
      "535 97 6\n",
      "535 97 7\n",
      "535 97 8\n",
      "535 97 9\n",
      "535 97 10\n",
      "535 97 11\n",
      "539 99 0\n",
      "539 99 1\n",
      "539 99 2\n",
      "539 99 3\n",
      "539 99 4\n",
      "539 99 5\n",
      "539 99 6\n",
      "539 99 7\n",
      "539 99 8\n",
      "539 99 9\n",
      "539 99 10\n",
      "539 99 11\n",
      "540 93 0\n",
      "540 93 1\n",
      "540 93 2\n",
      "540 93 3\n",
      "540 93 4\n",
      "540 93 5\n",
      "540 93 6\n",
      "540 93 7\n",
      "540 93 8\n",
      "540 93 9\n",
      "540 93 10\n",
      "540 93 11\n",
      "705 0 3\n",
      "705 1 3\n",
      "707 0 3\n",
      "707 1 3\n",
      "708 0 3\n",
      "708 1 3\n",
      "709 0 3\n",
      "709 1 3\n",
      "710 0 3\n",
      "710 1 3\n",
      "711 0 3\n",
      "711 1 3\n",
      "713 0 3\n",
      "713 1 3\n",
      "714 0 3\n",
      "714 1 3\n",
      "717 0 3\n",
      "717 1 3\n",
      "718 0 3\n",
      "718 1 3\n",
      "719 0 3\n",
      "719 1 3\n",
      "729 0 3\n",
      "729 1 3\n",
      "731 0 3\n",
      "731 1 3\n",
      "732 0 3\n",
      "732 1 3\n",
      "743 0 3\n",
      "744 0 3\n",
      "744 1 3\n",
      "745 0 3\n",
      "745 1 3\n",
      "746 0 3\n",
      "746 1 3\n",
      "747 0 0\n",
      "747 0 2\n",
      "747 0 3\n",
      "747 1 0\n",
      "747 1 2\n",
      "747 1 3\n",
      "756 0 0\n",
      "756 0 2\n",
      "756 0 3\n",
      "756 1 0\n",
      "756 1 2\n",
      "756 1 3\n",
      "767 0 0\n",
      "767 0 2\n",
      "767 0 3\n",
      "767 1 0\n",
      "767 1 2\n",
      "767 1 3\n",
      "773 96 0\n",
      "773 96 1\n",
      "773 96 2\n",
      "773 96 3\n",
      "773 96 4\n",
      "773 96 5\n",
      "773 96 6\n",
      "773 96 7\n",
      "773 96 8\n",
      "773 96 9\n",
      "773 96 10\n",
      "773 96 11\n",
      "786 0 3\n",
      "786 1 3\n",
      "793 0 0\n",
      "793 0 2\n",
      "793 0 3\n",
      "793 1 0\n",
      "793 1 2\n",
      "793 1 3\n",
      "795 0 5\n",
      "795 1 5\n",
      "795 96 0\n",
      "795 96 1\n",
      "795 96 2\n",
      "795 96 3\n",
      "795 96 4\n",
      "795 96 5\n",
      "795 96 6\n",
      "795 96 7\n",
      "795 96 8\n",
      "795 96 9\n",
      "795 96 10\n",
      "795 96 11\n",
      "796 0 4\n",
      "796 0 5\n",
      "796 1 4\n",
      "796 1 5\n",
      "796 94 0\n",
      "796 94 1\n",
      "796 94 2\n",
      "796 94 3\n",
      "796 94 4\n",
      "796 94 5\n",
      "796 94 6\n",
      "796 94 7\n",
      "796 94 8\n",
      "796 94 9\n",
      "796 94 10\n",
      "796 94 11\n",
      "797 0 5\n",
      "797 1 5\n",
      "803 94 0\n",
      "803 94 1\n",
      "803 94 2\n",
      "803 94 3\n",
      "803 94 4\n",
      "803 94 5\n",
      "803 94 6\n",
      "803 94 7\n",
      "803 94 8\n",
      "803 94 9\n",
      "803 94 10\n",
      "803 94 11\n",
      "803 98 0\n",
      "803 98 1\n",
      "803 98 2\n",
      "803 98 3\n",
      "803 98 4\n",
      "803 98 5\n",
      "803 98 6\n",
      "803 98 7\n",
      "803 98 8\n",
      "803 98 9\n",
      "803 98 10\n",
      "803 98 11\n",
      "803 103 0\n",
      "803 103 1\n",
      "803 103 2\n",
      "803 103 3\n",
      "803 103 4\n",
      "803 103 5\n",
      "803 103 6\n",
      "803 103 7\n",
      "803 103 8\n",
      "803 103 9\n",
      "803 103 10\n",
      "803 103 11\n",
      "803 108 0\n",
      "803 108 1\n",
      "803 108 2\n",
      "803 108 3\n",
      "803 108 4\n",
      "803 108 5\n",
      "803 108 6\n",
      "803 108 7\n",
      "803 108 8\n",
      "803 108 9\n",
      "803 108 10\n",
      "803 108 11\n",
      "804 92 0\n",
      "804 92 1\n",
      "804 92 2\n",
      "804 92 3\n",
      "804 92 4\n",
      "804 92 5\n",
      "804 92 6\n",
      "804 92 7\n",
      "804 92 8\n",
      "804 92 9\n",
      "804 92 10\n",
      "804 92 11\n",
      "804 95 0\n",
      "804 95 1\n",
      "804 95 2\n",
      "804 95 3\n",
      "804 95 4\n",
      "804 95 5\n",
      "804 95 6\n",
      "804 95 7\n",
      "804 95 8\n",
      "804 95 9\n",
      "804 95 10\n",
      "804 95 11\n",
      "805 0 5\n",
      "806 102 0\n",
      "806 102 1\n",
      "806 102 2\n",
      "806 102 3\n",
      "806 102 4\n",
      "806 102 5\n",
      "806 102 6\n",
      "806 102 7\n",
      "806 102 8\n",
      "806 102 9\n",
      "806 102 10\n",
      "806 102 11\n",
      "806 104 0\n",
      "806 104 1\n",
      "806 104 2\n",
      "806 104 3\n",
      "806 104 4\n",
      "806 104 5\n",
      "806 104 6\n",
      "806 104 7\n",
      "806 104 8\n",
      "806 104 9\n",
      "806 104 10\n",
      "806 104 11\n",
      "807 103 0\n",
      "807 103 1\n",
      "807 103 2\n",
      "807 103 3\n",
      "807 103 4\n",
      "807 103 5\n",
      "807 103 6\n",
      "807 103 7\n",
      "807 103 8\n",
      "807 103 9\n",
      "807 103 10\n",
      "807 103 11\n",
      "807 106 0\n",
      "807 106 1\n",
      "807 106 2\n",
      "807 106 3\n",
      "807 106 4\n",
      "807 106 5\n",
      "807 106 6\n",
      "807 106 7\n",
      "807 106 8\n",
      "807 106 9\n",
      "807 106 10\n",
      "807 106 11\n",
      "809 92 0\n",
      "809 92 1\n",
      "809 92 2\n",
      "809 92 3\n",
      "809 92 4\n",
      "809 92 5\n",
      "809 92 6\n",
      "809 92 7\n",
      "809 92 8\n",
      "809 92 9\n",
      "809 92 10\n",
      "809 92 11\n",
      "809 105 0\n",
      "809 105 1\n",
      "809 105 2\n",
      "809 105 3\n",
      "809 105 4\n",
      "809 105 5\n",
      "809 105 6\n",
      "809 105 7\n",
      "809 105 8\n",
      "809 105 9\n",
      "809 105 10\n",
      "809 105 11\n",
      "1508 0 3\n",
      "1508 0 5\n",
      "1508 1 3\n",
      "1508 1 5\n",
      "1509 0 3\n",
      "1509 0 5\n",
      "1509 1 3\n",
      "1509 1 5\n",
      "1510 0 3\n",
      "1510 0 5\n",
      "1510 1 3\n",
      "1510 1 5\n",
      "1511 0 3\n",
      "1511 0 5\n",
      "1511 1 3\n",
      "1511 1 5\n",
      "1512 0 3\n",
      "1512 0 5\n",
      "1512 1 3\n",
      "1512 1 5\n",
      "1513 0 3\n",
      "1513 0 5\n",
      "1513 1 3\n",
      "1513 1 5\n",
      "1514 0 4\n",
      "1514 0 5\n",
      "1514 1 4\n",
      "1514 1 5\n",
      "1515 0 4\n",
      "1515 0 5\n",
      "1515 1 4\n",
      "1515 1 5\n",
      "1516 0 4\n",
      "1516 0 5\n",
      "1516 1 4\n",
      "1516 1 5\n",
      "1524 0 3\n",
      "1524 0 5\n",
      "1524 1 3\n",
      "1524 1 5\n",
      "1525 0 3\n",
      "1525 0 5\n",
      "1525 1 3\n",
      "1525 1 5\n",
      "1528 0 5\n",
      "1528 1 5\n",
      "1529 0 4\n",
      "1529 0 5\n",
      "1529 1 4\n",
      "1529 1 5\n",
      "1530 0 4\n",
      "1530 0 5\n",
      "1530 1 4\n",
      "1530 1 5\n",
      "1531 0 4\n",
      "1531 0 5\n",
      "1531 1 4\n",
      "1531 1 5\n",
      "1532 0 4\n",
      "1532 0 5\n",
      "1532 1 4\n",
      "1532 1 5\n",
      "1533 0 5\n",
      "1533 1 5\n",
      "1534 0 5\n",
      "1534 1 5\n",
      "1535 0 3\n",
      "1535 0 5\n",
      "1535 1 3\n",
      "1535 1 5\n",
      "1536 0 3\n",
      "1536 0 5\n",
      "1536 1 3\n",
      "1536 1 5\n",
      "1537 0 3\n",
      "1537 0 5\n",
      "1537 1 3\n",
      "1537 1 5\n",
      "1538 0 3\n",
      "1538 0 5\n",
      "1538 1 3\n",
      "1538 1 5\n",
      "1539 0 3\n",
      "1539 0 5\n",
      "1539 1 3\n",
      "1539 1 5\n",
      "1541 0 0\n",
      "1541 0 2\n",
      "1541 0 3\n",
      "1541 1 0\n",
      "1541 1 2\n",
      "1541 1 3\n",
      "1545 0 5\n",
      "1545 1 5\n",
      "1546 0 4\n",
      "1546 0 5\n",
      "1546 1 4\n",
      "1546 1 5\n",
      "1548 0 4\n",
      "1548 0 5\n",
      "1548 1 4\n",
      "1548 1 5\n",
      "1551 0 3\n",
      "1551 0 5\n",
      "1551 1 3\n",
      "1551 1 5\n",
      "1552 0 3\n",
      "1552 0 5\n",
      "1552 1 3\n",
      "1552 1 5\n",
      "1553 0 3\n",
      "1553 0 5\n",
      "1553 1 3\n",
      "1553 1 5\n",
      "1554 0 3\n",
      "1554 0 5\n",
      "1554 1 3\n",
      "1554 1 5\n",
      "1555 0 3\n",
      "1555 1 3\n",
      "1556 0 3\n",
      "1556 0 5\n",
      "1556 1 3\n",
      "1556 1 5\n",
      "1557 0 3\n",
      "1557 0 5\n",
      "1557 1 3\n",
      "1557 1 5\n",
      "1558 0 3\n",
      "1558 0 5\n",
      "1558 1 3\n",
      "1558 1 5\n",
      "1559 0 4\n",
      "1559 0 5\n",
      "1559 1 4\n",
      "1559 1 5\n",
      "1560 0 4\n",
      "1560 0 5\n",
      "1560 1 4\n",
      "1560 1 5\n",
      "1567 0 3\n",
      "1567 1 3\n",
      "1568 0 3\n",
      "1568 0 5\n",
      "1568 1 3\n",
      "1568 1 5\n",
      "1569 0 3\n",
      "1569 0 5\n",
      "1569 1 3\n",
      "1569 1 5\n",
      "1570 0 3\n",
      "1570 0 5\n",
      "1570 1 3\n",
      "1570 1 5\n",
      "1571 0 3\n",
      "1571 0 5\n",
      "1571 1 3\n",
      "1571 1 5\n",
      "1572 0 4\n",
      "1572 0 5\n",
      "1572 1 4\n",
      "1572 1 5\n",
      "1573 0 4\n",
      "1573 0 5\n",
      "1573 1 4\n",
      "1573 1 5\n",
      "1574 0 5\n",
      "1574 1 5\n",
      "1575 0 4\n",
      "1575 0 5\n",
      "1575 1 4\n",
      "1575 1 5\n",
      "1576 0 3\n",
      "1576 1 3\n",
      "1577 0 3\n",
      "1577 0 5\n",
      "1577 1 3\n",
      "1577 1 5\n",
      "1578 0 3\n",
      "1578 0 5\n",
      "1578 1 3\n",
      "1578 1 5\n",
      "1579 0 3\n",
      "1579 0 5\n",
      "1579 1 3\n",
      "1579 1 5\n",
      "1580 0 3\n",
      "1580 0 5\n",
      "1580 1 3\n",
      "1580 1 5\n",
      "1581 0 3\n",
      "1581 0 5\n",
      "1584 0 4\n",
      "1584 0 5\n",
      "1584 1 4\n",
      "1584 1 5\n",
      "1585 0 4\n",
      "1585 0 5\n",
      "1585 1 4\n",
      "1585 1 5\n",
      "1586 0 5\n",
      "1586 1 5\n",
      "1587 0 4\n",
      "1587 0 5\n",
      "1587 1 4\n",
      "1587 1 5\n",
      "1588 0 4\n",
      "1588 0 5\n",
      "1588 1 4\n",
      "1588 1 5\n",
      "1589 0 5\n",
      "1589 1 5\n",
      "1590 0 4\n",
      "1590 0 5\n",
      "1590 1 4\n",
      "1590 1 5\n",
      "1591 0 5\n",
      "1591 1 5\n",
      "1592 0 5\n",
      "1592 1 5\n",
      "1593 0 5\n",
      "1593 1 5\n",
      "1594 0 5\n",
      "1594 1 5\n",
      "1595 0 3\n",
      "1595 0 5\n",
      "1595 1 3\n",
      "1595 1 5\n",
      "1602 0 4\n",
      "1602 0 5\n",
      "1602 1 4\n",
      "1602 1 5\n",
      "1603 0 4\n",
      "1603 0 5\n",
      "1603 1 4\n",
      "1603 1 5\n",
      "1604 0 4\n",
      "1604 0 5\n",
      "1604 1 4\n",
      "1604 1 5\n",
      "1605 0 4\n",
      "1605 0 5\n",
      "1605 1 4\n",
      "1605 1 5\n",
      "1606 0 4\n",
      "1606 0 5\n",
      "1606 1 4\n",
      "1606 1 5\n",
      "1607 0 4\n",
      "1607 0 5\n",
      "1607 1 4\n",
      "1607 1 5\n",
      "1610 0 5\n",
      "1610 1 5\n",
      "1611 98 0\n",
      "1611 98 1\n",
      "1611 98 2\n",
      "1611 98 3\n",
      "1611 98 4\n",
      "1611 98 5\n",
      "1611 98 6\n",
      "1611 98 7\n",
      "1611 98 8\n",
      "1611 98 9\n",
      "1611 98 10\n",
      "1611 98 11\n",
      "1611 100 0\n",
      "1611 100 1\n",
      "1611 100 2\n",
      "1611 100 3\n",
      "1611 100 4\n",
      "1611 100 5\n",
      "1611 100 6\n",
      "1611 100 7\n",
      "1611 100 8\n",
      "1611 100 9\n",
      "1611 100 10\n",
      "1611 100 11\n",
      "1612 93 0\n",
      "1612 93 1\n",
      "1612 93 2\n",
      "1612 93 3\n",
      "1612 93 4\n",
      "1612 93 5\n",
      "1612 93 6\n",
      "1612 93 7\n",
      "1612 93 8\n",
      "1612 93 9\n",
      "1612 93 10\n",
      "1612 93 11\n",
      "1612 98 0\n",
      "1612 98 1\n",
      "1612 98 2\n",
      "1612 98 3\n",
      "1612 98 4\n",
      "1612 98 5\n",
      "1612 98 6\n",
      "1612 98 7\n",
      "1612 98 8\n",
      "1612 98 9\n",
      "1612 98 10\n",
      "1612 98 11\n",
      "1613 97 0\n",
      "1613 97 1\n",
      "1613 97 2\n",
      "1613 97 3\n",
      "1613 97 4\n",
      "1613 97 5\n",
      "1613 97 6\n",
      "1613 97 7\n",
      "1613 97 8\n",
      "1613 97 9\n",
      "1613 97 10\n",
      "1613 97 11\n",
      "1614 97 0\n",
      "1614 97 1\n",
      "1614 97 2\n",
      "1614 97 3\n",
      "1614 97 4\n",
      "1614 97 5\n",
      "1614 97 6\n",
      "1614 97 7\n",
      "1614 97 8\n",
      "1614 97 9\n",
      "1614 97 10\n",
      "1614 97 11\n",
      "1615 0 3\n",
      "1619 0 5\n",
      "1620 0 4\n",
      "1620 0 5\n",
      "1620 1 4\n",
      "1620 1 5\n",
      "1620 104 0\n",
      "1620 104 1\n",
      "1620 104 2\n",
      "1620 104 3\n",
      "1620 104 4\n",
      "1620 104 5\n",
      "1620 104 6\n",
      "1620 104 7\n",
      "1620 104 8\n",
      "1620 104 9\n",
      "1620 104 10\n",
      "1620 104 11\n",
      "1621 0 4\n",
      "1621 0 5\n",
      "1621 1 4\n",
      "1621 1 5\n",
      "1621 96 0\n",
      "1621 96 1\n",
      "1621 96 2\n",
      "1621 96 3\n",
      "1621 96 4\n",
      "1621 96 5\n",
      "1621 96 6\n",
      "1621 96 7\n",
      "1621 96 8\n",
      "1621 96 9\n",
      "1621 96 10\n",
      "1621 96 11\n",
      "1622 0 4\n",
      "1622 0 5\n",
      "1622 1 5\n",
      "1624 98 0\n",
      "1624 98 1\n",
      "1624 98 2\n",
      "1624 98 3\n",
      "1624 98 4\n",
      "1624 98 5\n",
      "1624 98 6\n",
      "1624 98 7\n",
      "1624 98 8\n",
      "1624 98 9\n",
      "1624 98 10\n",
      "1624 98 11\n",
      "1625 0 1\n",
      "1625 0 4\n",
      "1625 0 5\n",
      "1625 97 0\n",
      "1625 97 1\n",
      "1625 97 2\n",
      "1625 97 3\n",
      "1625 97 4\n",
      "1625 97 5\n",
      "1625 97 6\n",
      "1625 97 7\n",
      "1625 97 8\n",
      "1625 97 9\n",
      "1625 97 10\n",
      "1625 97 11\n",
      "1626 93 0\n",
      "1626 93 1\n",
      "1626 93 2\n",
      "1626 93 3\n",
      "1626 93 4\n",
      "1626 93 5\n",
      "1626 93 6\n",
      "1626 93 7\n",
      "1626 93 8\n",
      "1626 93 9\n",
      "1626 93 10\n",
      "1626 93 11\n",
      "1626 97 0\n",
      "1626 97 1\n",
      "1626 97 2\n",
      "1626 97 3\n",
      "1626 97 4\n",
      "1626 97 5\n",
      "1626 97 6\n",
      "1626 97 7\n",
      "1626 97 8\n",
      "1626 97 9\n",
      "1626 97 10\n",
      "1626 97 11\n",
      "1644 0 3\n",
      "1644 1 3\n",
      "1645 0 3\n",
      "1645 1 3\n",
      "1652 0 5\n",
      "1652 1 5\n",
      "1653 0 3\n",
      "1653 1 3\n",
      "1660 0 3\n",
      "1660 1 3\n",
      "1661 100 0\n",
      "1661 100 1\n",
      "1661 100 2\n",
      "1661 100 3\n",
      "1661 100 4\n",
      "1661 100 5\n",
      "1661 100 6\n",
      "1661 100 7\n",
      "1661 100 8\n",
      "1661 100 9\n",
      "1661 100 10\n",
      "1661 100 11\n",
      "1670 0 0\n",
      "1670 0 2\n",
      "1670 0 3\n",
      "1677 101 0\n",
      "1677 101 1\n",
      "1677 101 2\n",
      "1677 101 3\n",
      "1677 101 4\n",
      "1677 101 5\n",
      "1677 101 6\n",
      "1677 101 7\n",
      "1677 101 8\n",
      "1677 101 9\n",
      "1677 101 10\n",
      "1677 101 11\n",
      "1680 0 3\n",
      "1680 1 3\n",
      "1683 100 0\n",
      "1683 100 1\n",
      "1683 100 2\n",
      "1683 100 3\n",
      "1683 100 4\n",
      "1683 100 5\n",
      "1683 100 6\n",
      "1683 100 7\n",
      "1683 100 8\n",
      "1683 100 9\n",
      "1683 100 10\n",
      "1683 100 11\n",
      "1701 0 3\n",
      "1701 1 3\n",
      "1702 0 3\n",
      "1702 1 3\n",
      "1703 0 3\n",
      "1703 1 3\n",
      "1704 0 3\n",
      "1704 1 3\n",
      "1709 0 3\n",
      "1709 1 3\n",
      "1714 0 0\n",
      "1714 0 2\n",
      "1714 0 3\n",
      "1714 1 0\n",
      "1714 1 2\n",
      "1714 1 3\n",
      "1720 101 0\n",
      "1720 101 1\n",
      "1720 101 2\n",
      "1720 101 3\n",
      "1720 101 4\n",
      "1720 101 5\n",
      "1720 101 6\n",
      "1720 101 7\n",
      "1720 101 8\n",
      "1720 101 9\n",
      "1720 101 10\n",
      "1720 101 11\n",
      "1721 101 0\n",
      "1721 101 1\n",
      "1721 101 2\n",
      "1721 101 3\n",
      "1721 101 4\n",
      "1721 101 5\n",
      "1721 101 6\n",
      "1721 101 7\n",
      "1721 101 8\n",
      "1721 101 9\n",
      "1721 101 10\n",
      "1721 101 11\n",
      "1722 0 3\n",
      "1722 1 3\n",
      "1722 101 0\n",
      "1722 101 1\n",
      "1722 101 2\n",
      "1722 101 3\n",
      "1722 101 4\n",
      "1722 101 5\n",
      "1722 101 6\n",
      "1722 101 7\n",
      "1722 101 8\n",
      "1722 101 9\n",
      "1722 101 10\n",
      "1722 101 11\n",
      "1724 0 3\n",
      "1724 1 3\n",
      "1725 104 0\n",
      "1725 104 1\n",
      "1725 104 2\n",
      "1725 104 3\n",
      "1725 104 4\n",
      "1725 104 5\n",
      "1725 104 6\n",
      "1725 104 7\n",
      "1725 104 8\n",
      "1725 104 9\n",
      "1725 104 10\n",
      "1725 104 11\n",
      "1726 0 3\n",
      "1726 101 0\n",
      "1726 101 1\n",
      "1726 101 2\n",
      "1726 101 3\n",
      "1726 101 4\n",
      "1726 101 5\n",
      "1726 101 6\n",
      "1726 101 7\n",
      "1726 101 8\n",
      "1726 101 9\n",
      "1726 101 10\n",
      "1726 101 11\n",
      "1727 0 3\n",
      "1729 100 0\n",
      "1729 100 1\n",
      "1729 100 2\n",
      "1729 100 3\n",
      "1729 100 4\n",
      "1729 100 5\n",
      "1729 100 6\n",
      "1729 100 7\n",
      "1729 100 8\n",
      "1729 100 9\n",
      "1729 100 10\n",
      "1729 100 11\n",
      "1730 0 3\n",
      "1730 1 3\n",
      "1730 100 0\n",
      "1730 100 1\n",
      "1730 100 2\n",
      "1730 100 3\n",
      "1730 100 4\n",
      "1730 100 5\n",
      "1730 100 6\n",
      "1730 100 7\n",
      "1730 100 8\n",
      "1730 100 9\n",
      "1730 100 10\n",
      "1730 100 11\n",
      "1730 102 0\n",
      "1730 102 1\n",
      "1730 102 2\n",
      "1730 102 3\n",
      "1730 102 4\n",
      "1730 102 5\n",
      "1730 102 6\n",
      "1730 102 7\n",
      "1730 102 8\n",
      "1730 102 9\n",
      "1730 102 10\n",
      "1730 102 11\n",
      "1731 0 3\n",
      "1731 1 3\n",
      "1732 0 3\n",
      "1732 1 3\n",
      "1733 0 3\n",
      "1733 1 3\n",
      "1736 0 3\n",
      "1736 1 3\n",
      "1736 103 0\n",
      "1736 103 1\n",
      "1736 103 2\n",
      "1736 103 3\n",
      "1736 103 4\n",
      "1736 103 5\n",
      "1736 103 6\n",
      "1736 103 7\n",
      "1736 103 8\n",
      "1736 103 9\n",
      "1736 103 10\n",
      "1736 103 11\n",
      "1737 0 0\n",
      "1737 0 2\n",
      "1737 0 3\n",
      "1738 0 3\n",
      "1739 99 0\n",
      "1739 99 1\n",
      "1739 99 2\n",
      "1739 99 3\n",
      "1739 99 4\n",
      "1739 99 5\n",
      "1739 99 6\n",
      "1739 99 7\n",
      "1739 99 8\n",
      "1739 99 9\n",
      "1739 99 10\n",
      "1739 99 11\n",
      "1743 0 2\n",
      "1743 0 3\n",
      "1743 1 2\n",
      "1743 1 3\n",
      "1746 0 5\n",
      "1746 99 0\n",
      "1746 99 1\n",
      "1746 99 2\n",
      "1746 99 3\n",
      "1746 99 4\n",
      "1746 99 5\n",
      "1746 99 6\n",
      "1746 99 7\n",
      "1746 99 8\n",
      "1746 99 9\n",
      "1746 99 10\n",
      "1746 99 11\n",
      "1754 98 0\n",
      "1754 98 1\n",
      "1754 98 2\n",
      "1754 98 3\n",
      "1754 98 4\n",
      "1754 98 5\n",
      "1754 98 6\n",
      "1754 98 7\n",
      "1754 98 8\n",
      "1754 98 9\n",
      "1754 98 10\n",
      "1754 98 11\n",
      "1754 100 0\n",
      "1754 100 1\n",
      "1754 100 2\n",
      "1754 100 3\n",
      "1754 100 4\n",
      "1754 100 5\n",
      "1754 100 6\n",
      "1754 100 7\n",
      "1754 100 8\n",
      "1754 100 9\n",
      "1754 100 10\n",
      "1754 100 11\n",
      "1757 100 0\n",
      "1757 100 1\n",
      "1757 100 2\n",
      "1757 100 3\n",
      "1757 100 4\n",
      "1757 100 5\n",
      "1757 100 6\n",
      "1757 100 7\n",
      "1757 100 8\n",
      "1757 100 9\n",
      "1757 100 10\n",
      "1757 100 11\n",
      "1764 0 0\n",
      "1764 0 2\n",
      "1764 0 3\n",
      "1768 0 4\n",
      "1768 0 5\n",
      "1768 1 4\n",
      "1768 1 5\n",
      "1769 0 4\n",
      "1769 0 5\n",
      "1769 1 4\n",
      "1769 1 5\n",
      "1770 0 4\n",
      "1770 0 5\n",
      "1770 1 4\n",
      "1770 1 5\n",
      "1771 0 4\n",
      "1771 0 5\n",
      "1771 1 4\n",
      "1771 1 5\n",
      "1772 0 4\n",
      "1772 0 5\n",
      "1772 1 4\n",
      "1772 1 5\n",
      "1775 0 3\n",
      "1775 1 3\n",
      "1775 106 0\n",
      "1775 106 1\n",
      "1775 106 2\n",
      "1775 106 3\n",
      "1775 106 4\n",
      "1775 106 5\n",
      "1775 106 6\n",
      "1775 106 7\n",
      "1775 106 8\n",
      "1775 106 9\n",
      "1775 106 10\n",
      "1775 106 11\n",
      "1780 99 0\n",
      "1780 99 1\n",
      "1780 99 2\n",
      "1780 99 3\n",
      "1780 99 4\n",
      "1780 99 5\n",
      "1780 99 6\n",
      "1780 99 7\n",
      "1780 99 8\n",
      "1780 99 9\n",
      "1780 99 10\n",
      "1780 99 11\n",
      "1781 99 0\n",
      "1781 99 1\n",
      "1781 99 2\n",
      "1781 99 3\n",
      "1781 99 4\n",
      "1781 99 5\n",
      "1781 99 6\n",
      "1781 99 7\n",
      "1781 99 8\n",
      "1781 99 9\n",
      "1781 99 10\n",
      "1781 99 11\n",
      "1782 0 5\n",
      "1782 1 5\n",
      "1782 101 0\n",
      "1782 101 1\n",
      "1782 101 2\n",
      "1782 101 3\n",
      "1782 101 4\n",
      "1782 101 5\n",
      "1782 101 6\n",
      "1782 101 7\n",
      "1782 101 8\n",
      "1782 101 9\n",
      "1782 101 10\n",
      "1782 101 11\n",
      "1783 0 5\n",
      "1783 1 5\n",
      "1783 100 0\n",
      "1783 100 1\n",
      "1783 100 2\n",
      "1783 100 3\n",
      "1783 100 4\n",
      "1783 100 5\n",
      "1783 100 6\n",
      "1783 100 7\n",
      "1783 100 8\n",
      "1783 100 9\n",
      "1783 100 10\n",
      "1783 100 11\n",
      "1784 0 5\n",
      "1784 1 5\n",
      "1784 100 0\n",
      "1784 100 1\n",
      "1784 100 2\n",
      "1784 100 3\n",
      "1784 100 4\n",
      "1784 100 5\n",
      "1784 100 6\n",
      "1784 100 7\n",
      "1784 100 8\n",
      "1784 100 9\n",
      "1784 100 10\n",
      "1784 100 11\n",
      "1786 0 5\n",
      "1786 98 0\n",
      "1786 98 1\n",
      "1786 98 2\n",
      "1786 98 3\n",
      "1786 98 4\n",
      "1786 98 5\n",
      "1786 98 6\n",
      "1786 98 7\n",
      "1786 98 8\n",
      "1786 98 9\n",
      "1786 98 10\n",
      "1786 98 11\n",
      "1787 104 0\n",
      "1787 104 1\n",
      "1787 104 2\n",
      "1787 104 3\n",
      "1787 104 4\n",
      "1787 104 5\n",
      "1787 104 6\n",
      "1787 104 7\n",
      "1787 104 8\n",
      "1787 104 9\n",
      "1787 104 10\n",
      "1787 104 11\n",
      "1788 91 0\n",
      "1788 91 1\n",
      "1788 91 2\n",
      "1788 91 3\n",
      "1788 91 4\n",
      "1788 91 5\n",
      "1788 91 6\n",
      "1788 91 7\n",
      "1788 91 8\n",
      "1788 91 9\n",
      "1788 91 10\n",
      "1788 91 11\n",
      "1790 94 0\n",
      "1790 94 1\n",
      "1790 94 2\n",
      "1790 94 3\n",
      "1790 94 4\n",
      "1790 94 5\n",
      "1790 94 6\n",
      "1790 94 7\n",
      "1790 94 8\n",
      "1790 94 9\n",
      "1790 94 10\n",
      "1790 94 11\n",
      "1791 101 0\n",
      "1791 101 1\n",
      "1791 101 2\n",
      "1791 101 3\n",
      "1791 101 4\n",
      "1791 101 5\n",
      "1791 101 6\n",
      "1791 101 7\n",
      "1791 101 8\n",
      "1791 101 9\n",
      "1791 101 10\n",
      "1791 101 11\n",
      "1791 112 0\n",
      "1791 112 1\n",
      "1791 112 2\n",
      "1791 112 3\n",
      "1791 112 4\n",
      "1791 112 5\n",
      "1791 112 6\n",
      "1791 112 7\n",
      "1791 112 8\n",
      "1791 112 9\n",
      "1791 112 10\n",
      "1791 112 11\n",
      "1793 0 5\n",
      "1793 1 5\n",
      "1794 0 5\n",
      "1794 1 5\n",
      "1795 0 5\n",
      "1795 1 5\n",
      "1795 101 0\n",
      "1795 101 1\n",
      "1795 101 2\n",
      "1795 101 3\n",
      "1795 101 4\n",
      "1795 101 5\n",
      "1795 101 6\n",
      "1795 101 7\n",
      "1795 101 8\n",
      "1795 101 9\n",
      "1795 101 10\n",
      "1795 101 11\n",
      "1796 0 3\n",
      "1796 0 5\n",
      "1796 1 5\n",
      "1797 0 4\n",
      "1797 0 5\n",
      "1797 1 5\n",
      "1797 102 0\n",
      "1797 102 1\n",
      "1797 102 2\n",
      "1797 102 3\n",
      "1797 102 4\n",
      "1797 102 5\n",
      "1797 102 6\n",
      "1797 102 7\n",
      "1797 102 8\n",
      "1797 102 9\n",
      "1797 102 10\n",
      "1797 102 11\n",
      "1798 0 3\n",
      "1798 0 5\n",
      "1798 1 3\n",
      "1798 1 5\n",
      "1798 100 0\n",
      "1798 100 1\n",
      "1798 100 2\n",
      "1798 100 3\n",
      "1798 100 4\n",
      "1798 100 5\n",
      "1798 100 6\n",
      "1798 100 7\n",
      "1798 100 8\n",
      "1798 100 9\n",
      "1798 100 10\n",
      "1798 100 11\n",
      "1798 102 0\n",
      "1798 102 1\n",
      "1798 102 2\n",
      "1798 102 3\n",
      "1798 102 4\n",
      "1798 102 5\n",
      "1798 102 6\n",
      "1798 102 7\n",
      "1798 102 8\n",
      "1798 102 9\n",
      "1798 102 10\n",
      "1798 102 11\n",
      "1798 109 0\n",
      "1798 109 1\n",
      "1798 109 2\n",
      "1798 109 3\n",
      "1798 109 4\n",
      "1798 109 5\n",
      "1798 109 6\n",
      "1798 109 7\n",
      "1798 109 8\n",
      "1798 109 9\n",
      "1798 109 10\n",
      "1798 109 11\n",
      "1799 0 5\n",
      "1799 1 5\n",
      "1799 102 0\n",
      "1799 102 1\n",
      "1799 102 2\n",
      "1799 102 3\n",
      "1799 102 4\n",
      "1799 102 5\n",
      "1799 102 6\n",
      "1799 102 7\n",
      "1799 102 8\n",
      "1799 102 9\n",
      "1799 102 10\n",
      "1799 102 11\n",
      "1800 0 5\n",
      "1800 1 5\n",
      "1800 99 0\n",
      "1800 99 1\n",
      "1800 99 2\n",
      "1800 99 3\n",
      "1800 99 4\n",
      "1800 99 5\n",
      "1800 99 6\n",
      "1800 99 7\n",
      "1800 99 8\n",
      "1800 99 9\n",
      "1800 99 10\n",
      "1800 99 11\n",
      "1800 101 0\n",
      "1800 101 1\n",
      "1800 101 2\n",
      "1800 101 3\n",
      "1800 101 4\n",
      "1800 101 5\n",
      "1800 101 6\n",
      "1800 101 7\n",
      "1800 101 8\n",
      "1800 101 9\n",
      "1800 101 10\n",
      "1800 101 11\n",
      "1802 90 0\n",
      "1802 90 1\n",
      "1802 90 2\n",
      "1802 90 3\n",
      "1802 90 4\n",
      "1802 90 5\n",
      "1802 90 6\n",
      "1802 90 7\n",
      "1802 90 8\n",
      "1802 90 9\n",
      "1802 90 10\n",
      "1802 90 11\n",
      "1804 101 0\n",
      "1804 101 1\n",
      "1804 101 2\n",
      "1804 101 3\n",
      "1804 101 4\n",
      "1804 101 5\n",
      "1804 101 6\n",
      "1804 101 7\n",
      "1804 101 8\n",
      "1804 101 9\n",
      "1804 101 10\n",
      "1804 101 11\n",
      "1805 100 0\n",
      "1805 100 1\n",
      "1805 100 2\n",
      "1805 100 3\n",
      "1805 100 4\n",
      "1805 100 5\n",
      "1805 100 6\n",
      "1805 100 7\n",
      "1805 100 8\n",
      "1805 100 9\n",
      "1805 100 10\n",
      "1805 100 11\n",
      "1807 95 0\n",
      "1807 95 1\n",
      "1807 95 2\n",
      "1807 95 3\n",
      "1807 95 4\n",
      "1807 95 5\n",
      "1807 95 6\n",
      "1807 95 7\n",
      "1807 95 8\n",
      "1807 95 9\n",
      "1807 95 10\n",
      "1807 95 11\n",
      "1807 100 0\n",
      "1807 100 1\n",
      "1807 100 2\n",
      "1807 100 3\n",
      "1807 100 4\n",
      "1807 100 5\n",
      "1807 100 6\n",
      "1807 100 7\n",
      "1807 100 8\n",
      "1807 100 9\n",
      "1807 100 10\n",
      "1807 100 11\n",
      "1808 0 4\n",
      "1808 0 5\n",
      "1808 1 4\n",
      "1808 1 5\n",
      "1808 100 0\n",
      "1808 100 1\n",
      "1808 100 2\n",
      "1808 100 3\n",
      "1808 100 4\n",
      "1808 100 5\n",
      "1808 100 6\n",
      "1808 100 7\n",
      "1808 100 8\n",
      "1808 100 9\n",
      "1808 100 10\n",
      "1808 100 11\n",
      "1809 0 5\n",
      "1809 1 5\n",
      "1809 101 0\n",
      "1809 101 1\n",
      "1809 101 2\n",
      "1809 101 3\n",
      "1809 101 4\n",
      "1809 101 5\n",
      "1809 101 6\n",
      "1809 101 7\n",
      "1809 101 8\n",
      "1809 101 9\n",
      "1809 101 10\n",
      "1809 101 11\n",
      "1810 0 5\n",
      "1810 1 5\n",
      "1810 102 0\n",
      "1810 102 1\n",
      "1810 102 2\n",
      "1810 102 3\n",
      "1810 102 4\n",
      "1810 102 5\n",
      "1810 102 6\n",
      "1810 102 7\n",
      "1810 102 8\n",
      "1810 102 9\n",
      "1810 102 10\n",
      "1810 102 11\n",
      "1811 0 4\n",
      "1811 0 5\n",
      "1811 1 4\n",
      "1811 1 5\n",
      "1811 103 0\n",
      "1811 103 1\n",
      "1811 103 2\n",
      "1811 103 3\n",
      "1811 103 4\n",
      "1811 103 5\n",
      "1811 103 6\n",
      "1811 103 7\n",
      "1811 103 8\n",
      "1811 103 9\n",
      "1811 103 10\n",
      "1811 103 11\n",
      "1811 106 0\n",
      "1811 106 1\n",
      "1811 106 2\n",
      "1811 106 3\n",
      "1811 106 4\n",
      "1811 106 5\n",
      "1811 106 6\n",
      "1811 106 7\n",
      "1811 106 8\n",
      "1811 106 9\n",
      "1811 106 10\n",
      "1811 106 11\n",
      "1811 113 0\n",
      "1811 113 1\n",
      "1811 113 2\n",
      "1811 113 3\n",
      "1811 113 4\n",
      "1811 113 5\n",
      "1811 113 6\n",
      "1811 113 7\n",
      "1811 113 8\n",
      "1811 113 9\n",
      "1811 113 10\n",
      "1811 113 11\n",
      "1812 100 0\n",
      "1812 100 1\n",
      "1812 100 2\n",
      "1812 100 3\n",
      "1812 100 4\n",
      "1812 100 5\n",
      "1812 100 6\n",
      "1812 100 7\n",
      "1812 100 8\n",
      "1812 100 9\n",
      "1812 100 10\n",
      "1812 100 11\n",
      "1812 103 0\n",
      "1812 103 1\n",
      "1812 103 2\n",
      "1812 103 3\n",
      "1812 103 4\n",
      "1812 103 5\n",
      "1812 103 6\n",
      "1812 103 7\n",
      "1812 103 8\n",
      "1812 103 9\n",
      "1812 103 10\n",
      "1812 103 11\n",
      "1813 100 0\n",
      "1813 100 1\n",
      "1813 100 2\n",
      "1813 100 3\n",
      "1813 100 4\n",
      "1813 100 5\n",
      "1813 100 6\n",
      "1813 100 7\n",
      "1813 100 8\n",
      "1813 100 9\n",
      "1813 100 10\n",
      "1813 100 11\n",
      "1814 100 0\n",
      "1814 100 1\n",
      "1814 100 2\n",
      "1814 100 3\n",
      "1814 100 4\n",
      "1814 100 5\n",
      "1814 100 6\n",
      "1814 100 7\n",
      "1814 100 8\n",
      "1814 100 9\n",
      "1814 100 10\n",
      "1814 100 11\n",
      "1814 105 0\n",
      "1814 105 1\n",
      "1814 105 2\n",
      "1814 105 3\n",
      "1814 105 4\n",
      "1814 105 5\n",
      "1814 105 6\n",
      "1814 105 7\n",
      "1814 105 8\n",
      "1814 105 9\n",
      "1814 105 10\n",
      "1814 105 11\n",
      "1815 102 0\n",
      "1815 102 1\n",
      "1815 102 2\n",
      "1815 102 3\n",
      "1815 102 4\n",
      "1815 102 5\n",
      "1815 102 6\n",
      "1815 102 7\n",
      "1815 102 8\n",
      "1815 102 9\n",
      "1815 102 10\n",
      "1815 102 11\n",
      "1817 97 0\n",
      "1817 97 1\n",
      "1817 97 2\n",
      "1817 97 3\n",
      "1817 97 4\n",
      "1817 97 5\n",
      "1817 97 6\n",
      "1817 97 7\n",
      "1817 97 8\n",
      "1817 97 9\n",
      "1817 97 10\n",
      "1817 97 11\n",
      "1818 90 0\n",
      "1818 90 1\n",
      "1818 90 2\n",
      "1818 90 3\n",
      "1818 90 4\n",
      "1818 90 5\n",
      "1818 90 6\n",
      "1818 90 7\n",
      "1818 90 8\n",
      "1818 90 9\n",
      "1818 90 10\n",
      "1818 90 11\n",
      "1818 98 0\n",
      "1818 98 1\n",
      "1818 98 2\n",
      "1818 98 3\n",
      "1818 98 4\n",
      "1818 98 5\n",
      "1818 98 6\n",
      "1818 98 7\n",
      "1818 98 8\n",
      "1818 98 9\n",
      "1818 98 10\n",
      "1818 98 11\n",
      "1818 102 0\n",
      "1818 102 1\n",
      "1818 102 2\n",
      "1818 102 3\n",
      "1818 102 4\n",
      "1818 102 5\n",
      "1818 102 6\n",
      "1818 102 7\n",
      "1818 102 8\n",
      "1818 102 9\n",
      "1818 102 10\n",
      "1818 102 11\n",
      "1818 104 0\n",
      "1818 104 1\n",
      "1818 104 2\n",
      "1818 104 3\n",
      "1818 104 4\n",
      "1818 104 5\n",
      "1818 104 6\n",
      "1818 104 7\n",
      "1818 104 8\n",
      "1818 104 9\n",
      "1818 104 10\n",
      "1818 104 11\n",
      "1819 96 0\n",
      "1819 96 1\n",
      "1819 96 2\n",
      "1819 96 3\n",
      "1819 96 4\n",
      "1819 96 5\n",
      "1819 96 6\n",
      "1819 96 7\n",
      "1819 96 8\n",
      "1819 96 9\n",
      "1819 96 10\n",
      "1819 96 11\n",
      "1821 99 0\n",
      "1821 99 1\n",
      "1821 99 2\n",
      "1821 99 3\n",
      "1821 99 4\n",
      "1821 99 5\n",
      "1821 99 6\n",
      "1821 99 7\n",
      "1821 99 8\n",
      "1821 99 9\n",
      "1821 99 10\n",
      "1821 99 11\n",
      "1821 103 0\n",
      "1821 103 1\n",
      "1821 103 2\n",
      "1821 103 3\n",
      "1821 103 4\n",
      "1821 103 5\n",
      "1821 103 6\n",
      "1821 103 7\n",
      "1821 103 8\n",
      "1821 103 9\n",
      "1821 103 10\n",
      "1821 103 11\n",
      "1822 99 0\n",
      "1822 99 1\n",
      "1822 99 2\n",
      "1822 99 3\n",
      "1822 99 4\n",
      "1822 99 5\n",
      "1822 99 6\n",
      "1822 99 7\n",
      "1822 99 8\n",
      "1822 99 9\n",
      "1822 99 10\n",
      "1822 99 11\n",
      "1822 102 0\n",
      "1822 102 1\n",
      "1822 102 2\n",
      "1822 102 3\n",
      "1822 102 4\n",
      "1822 102 5\n",
      "1822 102 6\n",
      "1822 102 7\n",
      "1822 102 8\n",
      "1822 102 9\n",
      "1822 102 10\n",
      "1822 102 11\n",
      "1822 107 0\n",
      "1822 107 1\n",
      "1822 107 2\n",
      "1822 107 3\n",
      "1822 107 4\n",
      "1822 107 5\n",
      "1822 107 6\n",
      "1822 107 7\n",
      "1822 107 8\n",
      "1822 107 9\n",
      "1822 107 10\n",
      "1822 107 11\n",
      "1822 110 0\n",
      "1822 110 1\n",
      "1822 110 2\n",
      "1822 110 3\n",
      "1822 110 4\n",
      "1822 110 5\n",
      "1822 110 6\n",
      "1822 110 7\n",
      "1822 110 8\n",
      "1822 110 9\n",
      "1822 110 10\n",
      "1822 110 11\n",
      "1823 98 0\n",
      "1823 98 1\n",
      "1823 98 2\n",
      "1823 98 3\n",
      "1823 98 4\n",
      "1823 98 5\n",
      "1823 98 6\n",
      "1823 98 7\n",
      "1823 98 8\n",
      "1823 98 9\n",
      "1823 98 10\n",
      "1823 98 11\n",
      "1823 107 0\n",
      "1823 107 1\n",
      "1823 107 2\n",
      "1823 107 3\n",
      "1823 107 4\n",
      "1823 107 5\n",
      "1823 107 6\n",
      "1823 107 7\n",
      "1823 107 8\n",
      "1823 107 9\n",
      "1823 107 10\n",
      "1823 107 11\n",
      "1824 97 0\n",
      "1824 97 1\n",
      "1824 97 2\n",
      "1824 97 3\n",
      "1824 97 4\n",
      "1824 97 5\n",
      "1824 97 6\n",
      "1824 97 7\n",
      "1824 97 8\n",
      "1824 97 9\n",
      "1824 97 10\n",
      "1824 97 11\n",
      "1824 100 0\n",
      "1824 100 1\n",
      "1824 100 2\n",
      "1824 100 3\n",
      "1824 100 4\n",
      "1824 100 5\n",
      "1824 100 6\n",
      "1824 100 7\n",
      "1824 100 8\n",
      "1824 100 9\n",
      "1824 100 10\n",
      "1824 100 11\n",
      "1824 105 0\n",
      "1824 105 1\n",
      "1824 105 2\n",
      "1824 105 3\n",
      "1824 105 4\n",
      "1824 105 5\n",
      "1824 105 6\n",
      "1824 105 7\n",
      "1824 105 8\n",
      "1824 105 9\n",
      "1824 105 10\n",
      "1824 105 11\n",
      "1825 90 0\n",
      "1825 90 1\n",
      "1825 90 2\n",
      "1825 90 3\n",
      "1825 90 4\n",
      "1825 90 5\n",
      "1825 90 6\n",
      "1825 90 7\n",
      "1825 90 8\n",
      "1825 90 9\n",
      "1825 90 10\n",
      "1825 90 11\n",
      "1825 99 0\n",
      "1825 99 1\n",
      "1825 99 2\n",
      "1825 99 3\n",
      "1825 99 4\n",
      "1825 99 5\n",
      "1825 99 6\n",
      "1825 99 7\n",
      "1825 99 8\n",
      "1825 99 9\n",
      "1825 99 10\n",
      "1825 99 11\n",
      "1826 0 5\n",
      "1826 1 5\n",
      "1827 0 4\n",
      "1827 0 5\n",
      "1827 1 5\n",
      "1827 98 0\n",
      "1827 98 1\n",
      "1827 98 2\n",
      "1827 98 3\n",
      "1827 98 4\n",
      "1827 98 5\n",
      "1827 98 6\n",
      "1827 98 7\n",
      "1827 98 8\n",
      "1827 98 9\n",
      "1827 98 10\n",
      "1827 98 11\n",
      "1827 100 0\n",
      "1827 100 1\n",
      "1827 100 2\n",
      "1827 100 3\n",
      "1827 100 4\n",
      "1827 100 5\n",
      "1827 100 6\n",
      "1827 100 7\n",
      "1827 100 8\n",
      "1827 100 9\n",
      "1827 100 10\n",
      "1827 100 11\n",
      "1828 0 5\n",
      "1828 1 5\n",
      "1829 0 4\n",
      "1829 0 5\n",
      "1829 1 4\n",
      "1829 1 5\n",
      "1829 99 0\n",
      "1829 99 1\n",
      "1829 99 2\n",
      "1829 99 3\n",
      "1829 99 4\n",
      "1829 99 5\n",
      "1829 99 6\n",
      "1829 99 7\n",
      "1829 99 8\n",
      "1829 99 9\n",
      "1829 99 10\n",
      "1829 99 11\n",
      "1830 99 0\n",
      "1830 99 1\n",
      "1830 99 2\n",
      "1830 99 3\n",
      "1830 99 4\n",
      "1830 99 5\n",
      "1830 99 6\n",
      "1830 99 7\n",
      "1830 99 8\n",
      "1830 99 9\n",
      "1830 99 10\n",
      "1830 99 11\n",
      "1830 105 0\n",
      "1830 105 1\n",
      "1830 105 2\n",
      "1830 105 3\n",
      "1830 105 4\n",
      "1830 105 5\n",
      "1830 105 6\n",
      "1830 105 7\n",
      "1830 105 8\n",
      "1830 105 9\n",
      "1830 105 10\n",
      "1830 105 11\n",
      "1831 0 5\n",
      "1831 100 0\n",
      "1831 100 1\n",
      "1831 100 2\n",
      "1831 100 3\n",
      "1831 100 4\n",
      "1831 100 5\n",
      "1831 100 6\n",
      "1831 100 7\n",
      "1831 100 8\n",
      "1831 100 9\n",
      "1831 100 10\n",
      "1831 100 11\n",
      "1831 106 0\n",
      "1831 106 1\n",
      "1831 106 2\n",
      "1831 106 3\n",
      "1831 106 4\n",
      "1831 106 5\n",
      "1831 106 6\n",
      "1831 106 7\n",
      "1831 106 8\n",
      "1831 106 9\n",
      "1831 106 10\n",
      "1831 106 11\n",
      "1831 110 0\n",
      "1831 110 1\n",
      "1831 110 2\n",
      "1831 110 3\n",
      "1831 110 4\n",
      "1831 110 5\n",
      "1831 110 6\n",
      "1831 110 7\n",
      "1831 110 8\n",
      "1831 110 9\n",
      "1831 110 10\n",
      "1831 110 11\n",
      "1832 149 0\n",
      "1832 149 1\n",
      "1832 149 2\n",
      "1832 149 3\n",
      "1832 149 4\n",
      "1832 149 5\n",
      "1832 149 6\n",
      "1832 149 7\n",
      "1832 149 8\n",
      "1832 149 9\n",
      "1832 149 10\n",
      "1832 149 11\n",
      "1833 100 0\n",
      "1833 100 1\n",
      "1833 100 2\n",
      "1833 100 3\n",
      "1833 100 4\n",
      "1833 100 5\n",
      "1833 100 6\n",
      "1833 100 7\n",
      "1833 100 8\n",
      "1833 100 9\n",
      "1833 100 10\n",
      "1833 100 11\n",
      "1834 0 0\n",
      "1834 0 2\n",
      "1834 0 3\n",
      "1834 0 5\n",
      "1834 1 0\n",
      "1834 1 2\n",
      "1834 1 3\n",
      "1834 1 5\n",
      "1834 98 0\n",
      "1834 98 1\n",
      "1834 98 2\n",
      "1834 98 3\n",
      "1834 98 4\n",
      "1834 98 5\n",
      "1834 98 6\n",
      "1834 98 7\n",
      "1834 98 8\n",
      "1834 98 9\n",
      "1834 98 10\n",
      "1834 98 11\n",
      "1836 102 0\n",
      "1836 102 1\n",
      "1836 102 2\n",
      "1836 102 3\n",
      "1836 102 4\n",
      "1836 102 5\n",
      "1836 102 6\n",
      "1836 102 7\n",
      "1836 102 8\n",
      "1836 102 9\n",
      "1836 102 10\n",
      "1836 102 11\n",
      "1838 93 0\n",
      "1838 93 1\n",
      "1838 93 2\n",
      "1838 93 3\n",
      "1838 93 4\n",
      "1838 93 5\n",
      "1838 93 6\n",
      "1838 93 7\n",
      "1838 93 8\n",
      "1838 93 9\n",
      "1838 93 10\n",
      "1838 93 11\n",
      "1838 100 0\n",
      "1838 100 1\n",
      "1838 100 2\n",
      "1838 100 3\n",
      "1838 100 4\n",
      "1838 100 5\n",
      "1838 100 6\n",
      "1838 100 7\n",
      "1838 100 8\n",
      "1838 100 9\n",
      "1838 100 10\n",
      "1838 100 11\n",
      "1839 0 5\n",
      "1842 95 0\n",
      "1842 95 1\n",
      "1842 95 2\n",
      "1842 95 3\n",
      "1842 95 4\n",
      "1842 95 5\n",
      "1842 95 6\n",
      "1842 95 7\n",
      "1842 95 8\n",
      "1842 95 9\n",
      "1842 95 10\n",
      "1842 95 11\n",
      "1842 103 0\n",
      "1842 103 1\n",
      "1842 103 2\n",
      "1842 103 3\n",
      "1842 103 4\n",
      "1842 103 5\n",
      "1842 103 6\n",
      "1842 103 7\n",
      "1842 103 8\n",
      "1842 103 9\n",
      "1842 103 10\n",
      "1842 103 11\n",
      "1843 98 0\n",
      "1843 98 1\n",
      "1843 98 2\n",
      "1843 98 3\n",
      "1843 98 4\n",
      "1843 98 5\n",
      "1843 98 6\n",
      "1843 98 7\n",
      "1843 98 8\n",
      "1843 98 9\n",
      "1843 98 10\n",
      "1843 98 11\n",
      "1844 97 0\n",
      "1844 97 1\n",
      "1844 97 2\n",
      "1844 97 3\n",
      "1844 97 4\n",
      "1844 97 5\n",
      "1844 97 6\n",
      "1844 97 7\n",
      "1844 97 8\n",
      "1844 97 9\n",
      "1844 97 10\n",
      "1844 97 11\n",
      "1845 97 0\n",
      "1845 97 1\n",
      "1845 97 2\n",
      "1845 97 3\n",
      "1845 97 4\n",
      "1845 97 5\n",
      "1845 97 6\n",
      "1845 97 7\n",
      "1845 97 8\n",
      "1845 97 9\n",
      "1845 97 10\n",
      "1845 97 11\n",
      "1845 99 0\n",
      "1845 99 1\n",
      "1845 99 2\n",
      "1845 99 3\n",
      "1845 99 4\n",
      "1845 99 5\n",
      "1845 99 6\n",
      "1845 99 7\n",
      "1845 99 8\n",
      "1845 99 9\n",
      "1845 99 10\n",
      "1845 99 11\n",
      "1845 105 0\n",
      "1845 105 1\n",
      "1845 105 2\n",
      "1845 105 3\n",
      "1845 105 4\n",
      "1845 105 5\n",
      "1845 105 6\n",
      "1845 105 7\n",
      "1845 105 8\n",
      "1845 105 9\n",
      "1845 105 10\n",
      "1845 105 11\n",
      "1846 91 0\n",
      "1846 91 1\n",
      "1846 91 2\n",
      "1846 91 3\n",
      "1846 91 4\n",
      "1846 91 5\n",
      "1846 91 6\n",
      "1846 91 7\n",
      "1846 91 8\n",
      "1846 91 9\n",
      "1846 91 10\n",
      "1846 91 11\n",
      "1846 99 0\n",
      "1846 99 1\n",
      "1846 99 2\n",
      "1846 99 3\n",
      "1846 99 4\n",
      "1846 99 5\n",
      "1846 99 6\n",
      "1846 99 7\n",
      "1846 99 8\n",
      "1846 99 9\n",
      "1846 99 10\n",
      "1846 99 11\n",
      "1848 97 0\n",
      "1848 97 1\n",
      "1848 97 2\n",
      "1848 97 3\n",
      "1848 97 4\n",
      "1848 97 5\n",
      "1848 97 6\n",
      "1848 97 7\n",
      "1848 97 8\n",
      "1848 97 9\n",
      "1848 97 10\n",
      "1848 97 11\n",
      "1848 101 0\n",
      "1848 101 1\n",
      "1848 101 2\n",
      "1848 101 3\n",
      "1848 101 4\n",
      "1848 101 5\n",
      "1848 101 6\n",
      "1848 101 7\n",
      "1848 101 8\n",
      "1848 101 9\n",
      "1848 101 10\n",
      "1848 101 11\n",
      "1849 97 0\n",
      "1849 97 1\n",
      "1849 97 2\n",
      "1849 97 3\n",
      "1849 97 4\n",
      "1849 97 5\n",
      "1849 97 6\n",
      "1849 97 7\n",
      "1849 97 8\n",
      "1849 97 9\n",
      "1849 97 10\n",
      "1849 97 11\n",
      "1849 99 0\n",
      "1849 99 1\n",
      "1849 99 2\n",
      "1849 99 3\n",
      "1849 99 4\n",
      "1849 99 5\n",
      "1849 99 6\n",
      "1849 99 7\n",
      "1849 99 8\n",
      "1849 99 9\n",
      "1849 99 10\n",
      "1849 99 11\n",
      "1850 0 4\n",
      "1850 0 5\n",
      "1850 1 5\n",
      "1850 101 0\n",
      "1850 101 1\n",
      "1850 101 2\n",
      "1850 101 3\n",
      "1850 101 4\n",
      "1850 101 5\n",
      "1850 101 6\n",
      "1850 101 7\n",
      "1850 101 8\n",
      "1850 101 9\n",
      "1850 101 10\n",
      "1850 101 11\n",
      "1851 0 5\n",
      "1851 1 5\n",
      "1851 101 0\n",
      "1851 101 1\n",
      "1851 101 2\n",
      "1851 101 3\n",
      "1851 101 4\n",
      "1851 101 5\n",
      "1851 101 6\n",
      "1851 101 7\n",
      "1851 101 8\n",
      "1851 101 9\n",
      "1851 101 10\n",
      "1851 101 11\n",
      "1852 0 4\n",
      "1852 0 5\n",
      "1852 1 4\n",
      "1852 1 5\n",
      "1852 98 0\n",
      "1852 98 1\n",
      "1852 98 2\n",
      "1852 98 3\n",
      "1852 98 4\n",
      "1852 98 5\n",
      "1852 98 6\n",
      "1852 98 7\n",
      "1852 98 8\n",
      "1852 98 9\n",
      "1852 98 10\n",
      "1852 98 11\n",
      "1852 101 0\n",
      "1852 101 1\n",
      "1852 101 2\n",
      "1852 101 3\n",
      "1852 101 4\n",
      "1852 101 5\n",
      "1852 101 6\n",
      "1852 101 7\n",
      "1852 101 8\n",
      "1852 101 9\n",
      "1852 101 10\n",
      "1852 101 11\n",
      "1853 0 4\n",
      "1853 0 5\n",
      "1853 1 4\n",
      "1853 1 5\n",
      "1853 100 0\n",
      "1853 100 1\n",
      "1853 100 2\n",
      "1853 100 3\n",
      "1853 100 4\n",
      "1853 100 5\n",
      "1853 100 6\n",
      "1853 100 7\n",
      "1853 100 8\n",
      "1853 100 9\n",
      "1853 100 10\n",
      "1853 100 11\n",
      "1854 98 0\n",
      "1854 98 1\n",
      "1854 98 2\n",
      "1854 98 3\n",
      "1854 98 4\n",
      "1854 98 5\n",
      "1854 98 6\n",
      "1854 98 7\n",
      "1854 98 8\n",
      "1854 98 9\n",
      "1854 98 10\n",
      "1854 98 11\n",
      "1856 98 0\n",
      "1856 98 1\n",
      "1856 98 2\n",
      "1856 98 3\n",
      "1856 98 4\n",
      "1856 98 5\n",
      "1856 98 6\n",
      "1856 98 7\n",
      "1856 98 8\n",
      "1856 98 9\n",
      "1856 98 10\n",
      "1856 98 11\n",
      "1857 0 5\n",
      "1857 1 5\n",
      "1857 99 0\n",
      "1857 99 1\n",
      "1857 99 2\n",
      "1857 99 3\n",
      "1857 99 4\n",
      "1857 99 5\n",
      "1857 99 6\n",
      "1857 99 7\n",
      "1857 99 8\n",
      "1857 99 9\n",
      "1857 99 10\n",
      "1857 99 11\n",
      "1858 0 3\n",
      "1858 0 5\n",
      "1858 1 3\n",
      "1858 1 5\n",
      "1858 98 0\n",
      "1858 98 1\n",
      "1858 98 2\n",
      "1858 98 3\n",
      "1858 98 4\n",
      "1858 98 5\n",
      "1858 98 6\n",
      "1858 98 7\n",
      "1858 98 8\n",
      "1858 98 9\n",
      "1858 98 10\n",
      "1858 98 11\n",
      "1858 100 0\n",
      "1858 100 1\n",
      "1858 100 2\n",
      "1858 100 3\n",
      "1858 100 4\n",
      "1858 100 5\n",
      "1858 100 6\n",
      "1858 100 7\n",
      "1858 100 8\n",
      "1858 100 9\n",
      "1858 100 10\n",
      "1858 100 11\n",
      "1859 0 4\n",
      "1859 0 5\n",
      "1859 1 5\n",
      "1860 0 5\n",
      "1860 1 5\n",
      "1861 0 3\n",
      "1861 0 5\n",
      "1861 1 3\n",
      "1861 1 5\n",
      "1862 0 5\n",
      "1862 1 5\n",
      "1862 100 0\n",
      "1862 100 1\n",
      "1862 100 2\n",
      "1862 100 3\n",
      "1862 100 4\n",
      "1862 100 5\n",
      "1862 100 6\n",
      "1862 100 7\n",
      "1862 100 8\n",
      "1862 100 9\n",
      "1862 100 10\n",
      "1862 100 11\n",
      "1864 97 0\n",
      "1864 97 1\n",
      "1864 97 2\n",
      "1864 97 3\n",
      "1864 97 4\n",
      "1864 97 5\n",
      "1864 97 6\n",
      "1864 97 7\n",
      "1864 97 8\n",
      "1864 97 9\n",
      "1864 97 10\n",
      "1864 97 11\n",
      "1865 99 0\n",
      "1865 99 1\n",
      "1865 99 2\n",
      "1865 99 3\n",
      "1865 99 4\n",
      "1865 99 5\n",
      "1865 99 6\n",
      "1865 99 7\n",
      "1865 99 8\n",
      "1865 99 9\n",
      "1865 99 10\n",
      "1865 99 11\n",
      "1868 97 0\n",
      "1868 97 1\n",
      "1868 97 2\n",
      "1868 97 3\n",
      "1868 97 4\n",
      "1868 97 5\n",
      "1868 97 6\n",
      "1868 97 7\n",
      "1868 97 8\n",
      "1868 97 9\n",
      "1868 97 10\n",
      "1868 97 11\n",
      "1869 90 0\n",
      "1869 90 1\n",
      "1869 90 2\n",
      "1869 90 3\n",
      "1869 90 4\n",
      "1869 90 5\n",
      "1869 90 6\n",
      "1869 90 7\n",
      "1869 90 8\n",
      "1869 90 9\n",
      "1869 90 10\n",
      "1869 90 11\n",
      "1869 103 0\n",
      "1869 103 1\n",
      "1869 103 2\n",
      "1869 103 3\n",
      "1869 103 4\n",
      "1869 103 5\n",
      "1869 103 6\n",
      "1869 103 7\n",
      "1869 103 8\n",
      "1869 103 9\n",
      "1869 103 10\n",
      "1869 103 11\n",
      "1871 0 5\n",
      "1871 1 5\n",
      "1871 99 0\n",
      "1871 99 1\n",
      "1871 99 2\n",
      "1871 99 3\n",
      "1871 99 4\n",
      "1871 99 5\n",
      "1871 99 6\n",
      "1871 99 7\n",
      "1871 99 8\n",
      "1871 99 9\n",
      "1871 99 10\n",
      "1871 99 11\n",
      "1872 0 5\n",
      "1872 1 5\n",
      "1872 97 0\n",
      "1872 97 1\n",
      "1872 97 2\n",
      "1872 97 3\n",
      "1872 97 4\n",
      "1872 97 5\n",
      "1872 97 6\n",
      "1872 97 7\n",
      "1872 97 8\n",
      "1872 97 9\n",
      "1872 97 10\n",
      "1872 97 11\n",
      "1873 0 4\n",
      "1873 0 5\n",
      "1873 1 4\n",
      "1873 1 5\n",
      "1874 0 4\n",
      "1874 0 5\n",
      "1874 1 4\n",
      "1874 1 5\n",
      "1874 101 0\n",
      "1874 101 1\n",
      "1874 101 2\n",
      "1874 101 3\n",
      "1874 101 4\n",
      "1874 101 5\n",
      "1874 101 6\n",
      "1874 101 7\n",
      "1874 101 8\n",
      "1874 101 9\n",
      "1874 101 10\n",
      "1874 101 11\n",
      "1875 0 5\n",
      "1875 1 5\n",
      "1875 99 0\n",
      "1875 99 1\n",
      "1875 99 2\n",
      "1875 99 3\n",
      "1875 99 4\n",
      "1875 99 5\n",
      "1875 99 6\n",
      "1875 99 7\n",
      "1875 99 8\n",
      "1875 99 9\n",
      "1875 99 10\n",
      "1875 99 11\n",
      "1876 0 3\n",
      "1883 96 0\n",
      "1883 96 1\n",
      "1883 96 2\n",
      "1883 96 3\n",
      "1883 96 4\n",
      "1883 96 5\n",
      "1883 96 6\n",
      "1883 96 7\n",
      "1883 96 8\n",
      "1883 96 9\n",
      "1883 96 10\n",
      "1883 96 11\n",
      "1883 99 0\n",
      "1883 99 1\n",
      "1883 99 2\n",
      "1883 99 3\n",
      "1883 99 4\n",
      "1883 99 5\n",
      "1883 99 6\n",
      "1883 99 7\n",
      "1883 99 8\n",
      "1883 99 9\n",
      "1883 99 10\n",
      "1883 99 11\n",
      "1884 94 0\n",
      "1884 94 1\n",
      "1884 94 2\n",
      "1884 94 3\n",
      "1884 94 4\n",
      "1884 94 5\n",
      "1884 94 6\n",
      "1884 94 7\n",
      "1884 94 8\n",
      "1884 94 9\n",
      "1884 94 10\n",
      "1884 94 11\n",
      "1884 105 0\n",
      "1884 105 1\n",
      "1884 105 2\n",
      "1884 105 3\n",
      "1884 105 4\n",
      "1884 105 5\n",
      "1884 105 6\n",
      "1884 105 7\n",
      "1884 105 8\n",
      "1884 105 9\n",
      "1884 105 10\n",
      "1884 105 11\n",
      "1885 92 0\n",
      "1885 92 1\n",
      "1885 92 2\n",
      "1885 92 3\n",
      "1885 92 4\n",
      "1885 92 5\n",
      "1885 92 6\n",
      "1885 92 7\n",
      "1885 92 8\n",
      "1885 92 9\n",
      "1885 92 10\n",
      "1885 92 11\n",
      "1885 98 0\n",
      "1885 98 1\n",
      "1885 98 2\n",
      "1885 98 3\n",
      "1885 98 4\n",
      "1885 98 5\n",
      "1885 98 6\n",
      "1885 98 7\n",
      "1885 98 8\n",
      "1885 98 9\n",
      "1885 98 10\n",
      "1885 98 11\n",
      "1886 93 0\n",
      "1886 93 1\n",
      "1886 93 2\n",
      "1886 93 3\n",
      "1886 93 4\n",
      "1886 93 5\n",
      "1886 93 6\n",
      "1886 93 7\n",
      "1886 93 8\n",
      "1886 93 9\n",
      "1886 93 10\n",
      "1886 93 11\n",
      "1886 103 0\n",
      "1886 103 1\n",
      "1886 103 2\n",
      "1886 103 3\n",
      "1886 103 4\n",
      "1886 103 5\n",
      "1886 103 6\n",
      "1886 103 7\n",
      "1886 103 8\n",
      "1886 103 9\n",
      "1886 103 10\n",
      "1886 103 11\n",
      "1887 0 3\n",
      "1887 0 5\n",
      "1887 1 3\n",
      "1887 1 5\n",
      "1888 0 3\n",
      "1888 0 5\n",
      "1888 1 3\n",
      "1888 1 5\n",
      "1888 134 0\n",
      "1888 134 1\n",
      "1888 134 2\n",
      "1888 134 3\n",
      "1888 134 4\n",
      "1888 134 5\n",
      "1888 134 6\n",
      "1888 134 7\n",
      "1888 134 8\n",
      "1888 134 9\n",
      "1888 134 10\n",
      "1888 134 11\n",
      "1888 135 0\n",
      "1888 135 1\n",
      "1888 135 2\n",
      "1888 135 3\n",
      "1888 135 4\n",
      "1888 135 5\n",
      "1888 135 6\n",
      "1888 135 7\n",
      "1888 135 8\n",
      "1888 135 9\n",
      "1888 135 10\n",
      "1888 135 11\n",
      "1888 136 0\n",
      "1888 136 1\n",
      "1888 136 2\n",
      "1888 136 3\n",
      "1888 136 4\n",
      "1888 136 5\n",
      "1888 136 6\n",
      "1888 136 7\n",
      "1888 136 8\n",
      "1888 136 9\n",
      "1888 136 10\n",
      "1888 136 11\n",
      "1888 137 0\n",
      "1888 137 1\n",
      "1888 137 2\n",
      "1888 137 3\n",
      "1888 137 4\n",
      "1888 137 5\n",
      "1888 137 6\n",
      "1888 137 7\n",
      "1888 137 8\n",
      "1888 137 9\n",
      "1888 137 10\n",
      "1888 137 11\n",
      "1888 138 0\n",
      "1888 138 1\n",
      "1888 138 2\n",
      "1888 138 3\n",
      "1888 138 4\n",
      "1888 138 5\n",
      "1888 138 6\n",
      "1888 138 7\n",
      "1888 138 8\n",
      "1888 138 9\n",
      "1888 138 10\n",
      "1888 138 11\n",
      "1888 139 0\n",
      "1888 139 1\n",
      "1888 139 2\n",
      "1888 139 3\n",
      "1888 139 4\n",
      "1888 139 5\n",
      "1888 139 6\n",
      "1888 139 7\n",
      "1888 139 8\n",
      "1888 139 9\n",
      "1888 139 10\n",
      "1888 139 11\n",
      "1888 140 0\n",
      "1888 140 1\n",
      "1888 140 2\n",
      "1888 140 3\n",
      "1888 140 4\n",
      "1888 140 5\n",
      "1888 140 6\n",
      "1888 140 7\n",
      "1888 140 8\n",
      "1888 140 9\n",
      "1888 140 10\n",
      "1888 140 11\n",
      "1888 141 0\n",
      "1888 141 1\n",
      "1888 141 2\n",
      "1888 141 3\n",
      "1888 141 4\n",
      "1888 141 5\n",
      "1888 141 6\n",
      "1888 141 7\n",
      "1888 141 8\n",
      "1888 141 9\n",
      "1888 141 10\n",
      "1888 141 11\n",
      "1888 142 0\n",
      "1888 142 1\n",
      "1888 142 2\n",
      "1888 142 3\n",
      "1888 142 4\n",
      "1888 142 5\n",
      "1888 142 6\n",
      "1888 142 7\n",
      "1888 142 8\n",
      "1888 142 9\n",
      "1888 142 10\n",
      "1888 142 11\n",
      "1888 143 0\n",
      "1888 143 1\n",
      "1888 143 2\n",
      "1888 143 3\n",
      "1888 143 4\n",
      "1888 143 5\n",
      "1888 143 6\n",
      "1888 143 7\n",
      "1888 143 8\n",
      "1888 143 9\n",
      "1888 143 10\n",
      "1888 143 11\n",
      "1888 144 0\n",
      "1888 144 1\n",
      "1888 144 2\n",
      "1888 144 3\n",
      "1888 144 4\n",
      "1888 144 5\n",
      "1888 144 6\n",
      "1888 144 7\n",
      "1888 144 8\n",
      "1888 144 9\n",
      "1888 144 10\n",
      "1888 144 11\n",
      "1888 145 0\n",
      "1888 145 1\n",
      "1888 145 2\n",
      "1888 145 3\n",
      "1888 145 4\n",
      "1888 145 5\n",
      "1888 145 6\n",
      "1888 145 7\n",
      "1888 145 8\n",
      "1888 145 9\n",
      "1888 145 10\n",
      "1888 145 11\n",
      "1888 146 0\n",
      "1888 146 1\n",
      "1888 146 2\n",
      "1888 146 3\n",
      "1888 146 4\n",
      "1888 146 5\n",
      "1888 146 6\n",
      "1888 146 7\n",
      "1888 146 8\n",
      "1888 146 9\n",
      "1888 146 10\n",
      "1888 146 11\n",
      "1888 147 0\n",
      "1888 147 1\n",
      "1888 147 2\n",
      "1888 147 3\n",
      "1888 147 4\n",
      "1888 147 5\n",
      "1888 147 6\n",
      "1888 147 7\n",
      "1888 147 8\n",
      "1888 147 9\n",
      "1888 147 10\n",
      "1888 147 11\n",
      "1888 148 0\n",
      "1888 148 1\n",
      "1888 148 2\n",
      "1888 148 3\n",
      "1888 148 4\n",
      "1888 148 5\n",
      "1888 148 6\n",
      "1888 148 7\n",
      "1888 148 8\n",
      "1888 148 9\n",
      "1888 148 10\n",
      "1888 148 11\n",
      "1888 149 0\n",
      "1888 149 1\n",
      "1888 149 2\n",
      "1888 149 3\n",
      "1888 149 4\n",
      "1888 149 5\n",
      "1888 149 6\n",
      "1888 149 7\n",
      "1888 149 8\n",
      "1888 149 9\n",
      "1888 149 10\n",
      "1888 149 11\n",
      "1889 0 3\n",
      "1889 0 5\n",
      "1889 1 3\n",
      "1889 1 5\n",
      "1890 0 3\n",
      "1890 1 3\n",
      "1895 134 0\n",
      "1895 134 1\n",
      "1895 134 2\n",
      "1895 134 3\n",
      "1895 134 4\n",
      "1895 134 5\n",
      "1895 134 6\n",
      "1895 134 7\n",
      "1895 134 8\n",
      "1895 134 9\n",
      "1895 134 10\n",
      "1895 134 11\n",
      "1895 135 0\n",
      "1895 135 1\n",
      "1895 135 2\n",
      "1895 135 3\n",
      "1895 135 4\n",
      "1895 135 5\n",
      "1895 135 6\n",
      "1895 135 7\n",
      "1895 135 8\n",
      "1895 135 9\n",
      "1895 135 10\n",
      "1895 135 11\n",
      "1895 136 0\n",
      "1895 136 1\n",
      "1895 136 2\n",
      "1895 136 3\n",
      "1895 136 4\n",
      "1895 136 5\n",
      "1895 136 6\n",
      "1895 136 7\n",
      "1895 136 8\n",
      "1895 136 9\n",
      "1895 136 10\n",
      "1895 136 11\n",
      "1895 137 0\n",
      "1895 137 1\n",
      "1895 137 2\n",
      "1895 137 3\n",
      "1895 137 4\n",
      "1895 137 5\n",
      "1895 137 6\n",
      "1895 137 7\n",
      "1895 137 8\n",
      "1895 137 9\n",
      "1895 137 10\n",
      "1895 137 11\n",
      "1895 138 0\n",
      "1895 138 1\n",
      "1895 138 2\n",
      "1895 138 3\n",
      "1895 138 4\n",
      "1895 138 5\n",
      "1895 138 6\n",
      "1895 138 7\n",
      "1895 138 8\n",
      "1895 138 9\n",
      "1895 138 10\n",
      "1895 138 11\n",
      "1895 139 0\n",
      "1895 139 1\n",
      "1895 139 2\n",
      "1895 139 3\n",
      "1895 139 4\n",
      "1895 139 5\n",
      "1895 139 6\n",
      "1895 139 7\n",
      "1895 139 8\n",
      "1895 139 9\n",
      "1895 139 10\n",
      "1895 139 11\n",
      "1895 140 0\n",
      "1895 140 1\n",
      "1895 140 2\n",
      "1895 140 3\n",
      "1895 140 4\n",
      "1895 140 5\n",
      "1895 140 6\n",
      "1895 140 7\n",
      "1895 140 8\n",
      "1895 140 9\n",
      "1895 140 10\n",
      "1895 140 11\n",
      "1895 141 0\n",
      "1895 141 1\n",
      "1895 141 2\n",
      "1895 141 3\n",
      "1895 141 4\n",
      "1895 141 5\n",
      "1895 141 6\n",
      "1895 141 7\n",
      "1895 141 8\n",
      "1895 141 9\n",
      "1895 141 10\n",
      "1895 141 11\n",
      "1895 142 0\n",
      "1895 142 1\n",
      "1895 142 2\n",
      "1895 142 3\n",
      "1895 142 4\n",
      "1895 142 5\n",
      "1895 142 6\n",
      "1895 142 7\n",
      "1895 142 8\n",
      "1895 142 9\n",
      "1895 142 10\n",
      "1895 142 11\n",
      "1895 143 0\n",
      "1895 143 1\n",
      "1895 143 2\n",
      "1895 143 3\n",
      "1895 143 4\n",
      "1895 143 5\n",
      "1895 143 6\n",
      "1895 143 7\n",
      "1895 143 8\n",
      "1895 143 9\n",
      "1895 143 10\n",
      "1895 143 11\n",
      "1895 144 0\n",
      "1895 144 1\n",
      "1895 144 2\n",
      "1895 144 3\n",
      "1895 144 4\n",
      "1895 144 5\n",
      "1895 144 6\n",
      "1895 144 7\n",
      "1895 144 8\n",
      "1895 144 9\n",
      "1895 144 10\n",
      "1895 144 11\n",
      "1895 145 0\n",
      "1895 145 1\n",
      "1895 145 2\n",
      "1895 145 3\n",
      "1895 145 4\n",
      "1895 145 5\n",
      "1895 145 6\n",
      "1895 145 7\n",
      "1895 145 8\n",
      "1895 145 9\n",
      "1895 145 10\n",
      "1895 145 11\n",
      "1895 146 0\n",
      "1895 146 1\n",
      "1895 146 2\n",
      "1895 146 3\n",
      "1895 146 4\n",
      "1895 146 5\n",
      "1895 146 6\n",
      "1895 146 7\n",
      "1895 146 8\n",
      "1895 146 9\n",
      "1895 146 10\n",
      "1895 146 11\n",
      "1895 147 0\n",
      "1895 147 1\n",
      "1895 147 2\n",
      "1895 147 3\n",
      "1895 147 4\n",
      "1895 147 5\n",
      "1895 147 6\n",
      "1895 147 7\n",
      "1895 147 8\n",
      "1895 147 9\n",
      "1895 147 10\n",
      "1895 147 11\n",
      "1895 148 0\n",
      "1895 148 1\n",
      "1895 148 2\n",
      "1895 148 3\n",
      "1895 148 4\n",
      "1895 148 5\n",
      "1895 148 6\n",
      "1895 148 7\n",
      "1895 148 8\n",
      "1895 148 9\n",
      "1895 148 10\n",
      "1895 148 11\n",
      "1895 149 0\n",
      "1895 149 1\n",
      "1895 149 2\n",
      "1895 149 3\n",
      "1895 149 4\n",
      "1895 149 5\n",
      "1895 149 6\n",
      "1895 149 7\n",
      "1895 149 8\n",
      "1895 149 9\n",
      "1895 149 10\n",
      "1895 149 11\n",
      "1896 0 1\n",
      "1896 0 4\n",
      "1896 0 5\n",
      "1896 1 1\n",
      "1896 1 4\n",
      "1896 1 5\n",
      "1898 0 0\n",
      "1898 0 2\n",
      "1898 0 3\n",
      "1898 1 0\n",
      "1898 1 2\n",
      "1898 1 3\n",
      "1899 95 0\n",
      "1899 95 1\n",
      "1899 95 2\n",
      "1899 95 3\n",
      "1899 95 4\n",
      "1899 95 5\n",
      "1899 95 6\n",
      "1899 95 7\n",
      "1899 95 8\n",
      "1899 95 9\n",
      "1899 95 10\n",
      "1899 95 11\n",
      "1900 0 5\n",
      "1900 1 5\n",
      "1900 94 0\n",
      "1900 94 1\n",
      "1900 94 2\n",
      "1900 94 3\n",
      "1900 94 4\n",
      "1900 94 5\n",
      "1900 94 6\n",
      "1900 94 7\n",
      "1900 94 8\n",
      "1900 94 9\n",
      "1900 94 10\n",
      "1900 94 11\n",
      "1913 96 0\n",
      "1913 96 1\n",
      "1913 96 2\n",
      "1913 96 3\n",
      "1913 96 4\n",
      "1913 96 5\n",
      "1913 96 6\n",
      "1913 96 7\n",
      "1913 96 8\n",
      "1913 96 9\n",
      "1913 96 10\n",
      "1913 96 11\n",
      "1914 97 0\n",
      "1914 97 1\n",
      "1914 97 2\n",
      "1914 97 3\n",
      "1914 97 4\n",
      "1914 97 5\n",
      "1914 97 6\n",
      "1914 97 7\n",
      "1914 97 8\n",
      "1914 97 9\n",
      "1914 97 10\n",
      "1914 97 11\n",
      "1915 97 0\n",
      "1915 97 1\n",
      "1915 97 2\n",
      "1915 97 3\n",
      "1915 97 4\n",
      "1915 97 5\n",
      "1915 97 6\n",
      "1915 97 7\n",
      "1915 97 8\n",
      "1915 97 9\n",
      "1915 97 10\n",
      "1915 97 11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-37ff223c6845>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mind_before\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0mind_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mind_after\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mind_after\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "M,N, nr_j, _ = data.shape\n",
    "#flat = np.flatten()\n",
    "#print(np.where(data[:,:,:, 0].flatten()==0 and data[:,:,:, 1]!=0))\n",
    "print(data.shape)\n",
    "data = data[:,:,:12,:]\n",
    "\n",
    "for i in range(M):\n",
    "    for j in range(N):\n",
    "        for k in range(12):\n",
    "            if k!=16 and data[i,j,k,0]==0:\n",
    "                if j<150:\n",
    "                    print(i,j,k)\n",
    "                ind  = np.where(data[i, :, k, 0]>0)[0]\n",
    "                if ind[-1]>j and ind[0]<j: #ind!=np.array([]) and \n",
    "                    #print(ind)\n",
    "                    ind_before = ind[ind<j][-1]\n",
    "                    ind_after = ind[ind>j][0]\n",
    "                    inter0 = np.linspace(data[i, ind_before, k, 0], data[i, ind_after, k, 0], ind_after-ind_before, endpoint = False)\n",
    "                    inter1 = np.linspace(data[i, ind_before, k, 1], data[i, ind_after, k, 1], ind_after-ind_before, endpoint = False)\n",
    "                    #print(ind)\n",
    "                    #print(i,j,k)\n",
    "                    #print(ind)\n",
    "                    #print(data[i,j])\n",
    "                    #print(data[i, j:ind_after, k, 0])\n",
    "                    data[i,j:ind_after,k,0]= inter0[1:]\n",
    "                    data[i,j:ind_after,k,1]= inter1[1:]\n",
    "                    #print(data[i,j])\n",
    "                elif ind[-1]>j:\n",
    "                    ind_before = ind[ind>j][0]  \n",
    "                    data[i,j,k,0] = data[i,ind_before,k,0]\n",
    "                    data[i,j,k,1] = data[i,ind_before,k,1]\n",
    "                elif ind[0]<j:\n",
    "                    ind_after = ind[ind<j][-1]\n",
    "                    data[i,j,k,0] = data[i,ind_after,k,0]\n",
    "                    data[i,j,k,1] = data[i,ind_after,k,1]\n",
    "                    \n",
    "print(data.shape)\n",
    "print(data)\n",
    "np.save(\"interpolated.npy\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fitness = [(524, ['relu', 0.0, True, 0.001, 0.0050000000000000001, 1024, 5, 512, 7, 0, 256]), (658, ['relu', 0.59999999999999998, False, 0.00050000000000000001, 0.00050000000000000001, 512, 7, 512, 11, 128, 0]), (146, ['leaky', 0.59999999999999998, False, 0.00050000000000000001, 0.0, 128, 11, 0, 7, 128, 256]), (390, ['leaky', 0.59999999999999998, False, 0.00050000000000000001, 0.0, 128, 3, 256, 3, 128, 0]), (12, ['relu', 0.59999999999999998, False, 0.00050000000000000001, 0.0050000000000000001, 256, 3, 0, 9, 0, 256]), (270, ['leaky', 0.59999999999999998, True, 0.00025000000000000001, 0.0, 0, 5, 128, 9, 128, 256]), (404, ['leaky', 0.0, False, 0.00050000000000000001, 0.00050000000000000001, 128, 11, 128, 9, 256, 128]), (1170, ['relu', 0.0, True, 0.00050000000000000001, 0.00050000000000000001, 512, 9, 128, 9, 1024, 0]), (650, ['leaky', 0.0, False, 0.0001, 0.0, 512, 5, 512, 5, 128, 128]), (1036, ['relu', 0.0, False, 0.001, 0.001, 128, 7, 0, 5, 1024, 1024])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing value by ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try on prednet (https://github.com/coxlab/prednet) but code did not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.load(\"interpolated.npy\")\n",
    "print(data.shape)\n",
    "\n",
    "source = np.zeros((6422*167))\n",
    "for i in range(6422):\n",
    "    source[i*167:(i+1)*167] = i\n",
    "\n",
    "data_images = np.reshape(data, (6422*167, 12,2))\n",
    "\n",
    "split1 = 6000*167\n",
    "split2 = 6400*167\n",
    "data_train = data_images[:split1]\n",
    "data_val = data_images[split1:split2]\n",
    "data_test = data_images[split2:]\n",
    "sources_train = source[:split1]\n",
    "sources_val = source[split1:split2]\n",
    "sources_test = source[split2:]\n",
    "\n",
    "print(data_train.shape, data_val.shape, data_test.shape, sources_train.shape, sources_val.shape, sources_test.shape)\n",
    "\n",
    "np.save(\"X_train.npy\", data_train)\n",
    "np.save(\"X_val.npy\", data_val)\n",
    "np.save(\"X_test.npy\", data_test)\n",
    "np.save(\"sources_train.npy\", sources_train)\n",
    "np.save(\"sources_val.npy\", sources_val)\n",
    "np.save(\"sources_test.npy\", sources_test)\n",
    "\n",
    "train_file = np.expand_dims(np.load(\"DATA_DIR/X_train.npy\"), axis = 3)\n",
    "train_sources = np.expand_dims(np.load(\"DATA_DIR/sources_train.npy\"), axis = 1) #os.path.join(DATA_DIR, 'sources_train.hkl\n",
    "val_file = np.expand_dims(np.load(\"DATA_DIR/X_val.npy\"), axis = 3) #os.path.join(DATA_DIR, 'X_val.hkl')\n",
    "val_sources = np.expand_dims(np.load(\"DATA_DIR/sources_val.npy\"), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
