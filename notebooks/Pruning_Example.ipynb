{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append('../Pose_Estimation')\n",
    "\n",
    "# Keras/TF dependencies\n",
    "import keras\n",
    "from keras.models import load_model, Sequential, Model\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# Common deps\n",
    "import numpy as np\n",
    "import cv2\n",
    "import util\n",
    "from config_reader import config_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_, model_ = config_reader()\n",
    "PYTORCH_WEIGHTS_PATH = model_['pytorch_model']\n",
    "TENSORFLOW_WEIGHTS_PATH = model_['tensorflow_model'].replace('./', '../Pose_Estimation/')\n",
    "USE_MODEL = model_['use_model']\n",
    "USE_GPU = param_['use_gpu']\n",
    "TORCH_CUDA = lambda x: x.cuda() if USE_GPU else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TensorFlowModel:\n",
    "    \"\"\"\n",
    "    TensorFlow model credited to Michal F.\n",
    "    (https://github.com/michalfaber/keras_Realtime_Multi-Person_Pose_Estimation)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, load_weights=True, compressed_model=None):\n",
    "        self.session = tf.Session()\n",
    "        # K.set_session(self.session)\n",
    "\n",
    "        def relu(x):\n",
    "            return Activation('relu')(x)\n",
    "\n",
    "        def conv(x, nf, ks, name):\n",
    "            x1 = Conv2D(nf, (ks, ks), padding='same', name=name)(x)\n",
    "            return x1\n",
    "\n",
    "        def pooling(x, ks, st, name):\n",
    "            x = MaxPooling2D((ks, ks), strides=(st, st), name=name)(x)\n",
    "            return x\n",
    "\n",
    "        def vgg_block(x):\n",
    "\n",
    "            # Block 1\n",
    "            x = conv(x, 64, 3, \"conv1_1\")\n",
    "            x = relu(x)\n",
    "            x = conv(x, 64, 3, \"conv1_2\")\n",
    "            x = relu(x)\n",
    "            x = pooling(x, 2, 2, \"pool1_1\")\n",
    "\n",
    "            # Block 2\n",
    "            x = conv(x, 128, 3, \"conv2_1\")\n",
    "            x = relu(x)\n",
    "            x = conv(x, 128, 3, \"conv2_2\")\n",
    "            x = relu(x)\n",
    "            x = pooling(x, 2, 2, \"pool2_1\")\n",
    "\n",
    "            # Block 3\n",
    "            x = conv(x, 256, 3, \"conv3_1\")\n",
    "            x = relu(x)\n",
    "            x = conv(x, 256, 3, \"conv3_2\")\n",
    "            x = relu(x)\n",
    "            x = conv(x, 256, 3, \"conv3_3\")\n",
    "            x = relu(x)\n",
    "            x = conv(x, 256, 3, \"conv3_4\")\n",
    "            x = relu(x)\n",
    "            x = pooling(x, 2, 2, \"pool3_1\")\n",
    "\n",
    "            # Block 4\n",
    "            x = conv(x, 512, 3, \"conv4_1\")\n",
    "            x = relu(x)\n",
    "            x = conv(x, 512, 3, \"conv4_2\")\n",
    "            x = relu(x)\n",
    "\n",
    "            # Additional non vgg layers\n",
    "            x = conv(x, 256, 3, \"conv4_3_CPM\")\n",
    "            x = relu(x)\n",
    "            x = conv(x, 128, 3, \"conv4_4_CPM\")\n",
    "            x = relu(x)\n",
    "\n",
    "            return x\n",
    "\n",
    "        def stage1_block(x, num_p, branch):\n",
    "\n",
    "            # Block 1\n",
    "            x = conv(x, 128, 3, \"conv5_1_CPM_L%d\" % branch)\n",
    "            x = relu(x)\n",
    "            x = conv(x, 128, 3, \"conv5_2_CPM_L%d\" % branch)\n",
    "            x = relu(x)\n",
    "            x = conv(x, 128, 3, \"conv5_3_CPM_L%d\" % branch)\n",
    "            x = relu(x)\n",
    "            x = conv(x, 512, 1, \"conv5_4_CPM_L%d\" % branch)\n",
    "            x = relu(x)\n",
    "            x = conv(x, num_p, 1, \"conv5_5_CPM_L%d\" % branch)\n",
    "\n",
    "            return x\n",
    "\n",
    "        def stageT_block(x, num_p, stage, branch, prefix='Heatmap'):\n",
    "\n",
    "            # Block 1\n",
    "            with tf.name_scope('%sBlock' % (prefix)):\n",
    "                x = conv(x, 128, 7, \"Mconv1_stage%d_L%d\" % (stage, branch))\n",
    "                x = relu(x)\n",
    "                x = conv(x, 128, 7, \"Mconv2_stage%d_L%d\" % (stage, branch))\n",
    "                x = relu(x)\n",
    "                x = conv(x, 128, 7, \"Mconv3_stage%d_L%d\" % (stage, branch))\n",
    "                x = relu(x)\n",
    "                x = conv(x, 128, 7, \"Mconv4_stage%d_L%d\" % (stage, branch))\n",
    "                x = relu(x)\n",
    "                x = conv(x, 128, 7, \"Mconv5_stage%d_L%d\" % (stage, branch))\n",
    "                x = relu(x)\n",
    "                x = conv(x, 128, 1, \"Mconv6_stage%d_L%d\" % (stage, branch))\n",
    "                x = relu(x)\n",
    "                x = conv(x, num_p, 1, \"Mconv7_stage%d_L%d\" % (stage, branch))\n",
    "\n",
    "            return x\n",
    "\n",
    "        # Hyper-parameters\n",
    "        input_shape = (None,None,3)\n",
    "        img_input = Input(shape=input_shape)\n",
    "\n",
    "        stages = 6\n",
    "        np_branch1 = 38\n",
    "        np_branch2 = 19\n",
    "\n",
    "        # output resize operations\n",
    "        # TODO: probably better of batch resizing at the end instead of doing them discretely\n",
    "        self.raw_heatmap = tf.placeholder(tf.float32, shape=(None, None, None, 19))\n",
    "        self.raw_paf = tf.placeholder(tf.float32, shape=(None, None, None, 38))\n",
    "        self.resize_size = tf.placeholder(tf.int32, shape=(2))\n",
    "\n",
    "        self.resize_heatmap = tf.transpose(tf.image.resize_images(self.raw_heatmap, self.resize_size, align_corners=True), perm=[0, 3, 1, 2])\n",
    "        self.resize_paf = tf.transpose(tf.image.resize_images(self.raw_paf, self.resize_size, align_corners=True), perm=[0, 3, 1, 2])\n",
    "\n",
    "        if compressed_model:\n",
    "            print '| Loading compressed model:', compressed_model\n",
    "            self.model = load_model(compressed_model)\n",
    "\n",
    "            compressed_weights = compressed_model.replace('.h5', '_w.h5')\n",
    "            self.model.load_weights(compressed_weights)\n",
    "            return\n",
    "\n",
    "        # VGG\n",
    "        with tf.name_scope('VggConvLayer'):\n",
    "            stage0_out = vgg_block(img_input)\n",
    "\n",
    "        # stage 1\n",
    "        with tf.name_scope('DualLayer%d' % (1)):\n",
    "            stage1_branch1_out = stage1_block(stage0_out, np_branch1, 1)\n",
    "            stage1_branch2_out = stage1_block(stage0_out, np_branch2, 2)\n",
    "            x = Concatenate()([stage1_branch1_out, stage1_branch2_out, stage0_out])\n",
    "\n",
    "        # stage t >= 2\n",
    "        for sn in range(2, stages + 1):\n",
    "            with tf.name_scope('DualLayer%d' % (sn)):\n",
    "                stageT_branch1_out = stageT_block(x, np_branch1, sn, 1, prefix='Heat')\n",
    "                stageT_branch2_out = stageT_block(x, np_branch2, sn, 2, prefix='PAF')\n",
    "                if (sn < stages):\n",
    "                    x = Concatenate()([stageT_branch1_out, stageT_branch2_out, stage0_out])\n",
    "\n",
    "        self.model = Model(img_input, [stageT_branch1_out, stageT_branch2_out])\n",
    "        if load_weights:\n",
    "            self.model.load_weights(TENSORFLOW_WEIGHTS_PATH)\n",
    "\n",
    "    def evaluate(self, oriImg, scale=1.0):\n",
    "        imageToTest = cv2.resize(oriImg, (0,0), fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "        imageToTest_padded, pad = util.padRightDownCorner(imageToTest, model_['stride'], model_['padValue'])\n",
    "        input_img = np.transpose(np.float32(imageToTest_padded[:,:,:,np.newaxis]), (3,0,1,2))/256 - 0.5;\n",
    "\n",
    "        output1, output2 = self.model.predict(input_img)\n",
    "\n",
    "        # Replicating bilinear upsampling to heatmaps procedure.\n",
    "        resize_dict = {\n",
    "            self.resize_size: [oriImg.shape[0], oriImg.shape[1]],\n",
    "            self.raw_heatmap: output2,\n",
    "            self.raw_paf: output1,\n",
    "        }\n",
    "\n",
    "        heatmap, paf = self.session.run([self.resize_heatmap, self.resize_paf], feed_dict=resize_dict)\n",
    "        heatmap, paf = heatmap[0], paf[0]\n",
    "\n",
    "        return (output1, output2), (heatmap, paf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = TensorFlowModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating filter rankings...\n",
      "Layer 2/181\n",
      "Layer 4/181\n",
      "Layer 7/181\n",
      "Layer 9/181\n",
      "Layer 12/181\n",
      "Layer 14/181\n",
      "Layer 16/181\n",
      "Layer 18/181\n",
      "Layer 21/181\n",
      "Layer 23/181\n",
      "Layer 25/181\n",
      "Layer 27/181\n",
      "Layer 29/181\n",
      "Layer 30/181\n",
      "Layer 33/181\n",
      "Layer 34/181\n",
      "Layer 37/181\n",
      "Layer 38/181\n",
      "Layer 41/181\n",
      "Layer 42/181\n",
      "Layer 45/181\n",
      "Layer 46/181\n",
      "Layer 48/181\n",
      "Layer 49/181\n",
      "Layer 52/181\n",
      "Layer 53/181\n",
      "Layer 56/181\n",
      "Layer 57/181\n",
      "Layer 60/181\n",
      "Layer 61/181\n",
      "Layer 64/181\n",
      "Layer 65/181\n",
      "Layer 68/181\n",
      "Layer 69/181\n",
      "Layer 72/181\n",
      "Layer 73/181\n",
      "Layer 75/181\n",
      "Layer 76/181\n",
      "Layer 79/181\n",
      "Layer 80/181\n",
      "Layer 83/181\n",
      "Layer 84/181\n",
      "Layer 87/181\n",
      "Layer 88/181\n",
      "Layer 91/181\n",
      "Layer 92/181\n",
      "Layer 95/181\n",
      "Layer 96/181\n",
      "Layer 99/181\n",
      "Layer 100/181\n",
      "Layer 102/181\n",
      "Layer 103/181\n",
      "Layer 106/181\n",
      "Layer 107/181\n",
      "Layer 110/181\n",
      "Layer 111/181\n",
      "Layer 114/181\n",
      "Layer 115/181\n",
      "Layer 118/181\n",
      "Layer 119/181\n",
      "Layer 122/181\n",
      "Layer 123/181\n",
      "Layer 126/181\n",
      "Layer 127/181\n",
      "Layer 129/181\n",
      "Layer 130/181\n",
      "Layer 133/181\n",
      "Layer 134/181\n",
      "Layer 137/181\n",
      "Layer 138/181\n",
      "Layer 141/181\n",
      "Layer 142/181\n",
      "Layer 145/181\n",
      "Layer 146/181\n",
      "Layer 149/181\n",
      "Layer 150/181\n",
      "Layer 153/181\n",
      "Layer 154/181\n",
      "Layer 156/181\n",
      "Layer 157/181\n",
      "Layer 160/181\n",
      "Layer 161/181\n",
      "Layer 164/181\n",
      "Layer 165/181\n",
      "Layer 168/181\n",
      "Layer 169/181\n",
      "Layer 172/181\n",
      "Layer 173/181\n",
      "Layer 176/181\n",
      "Layer 177/181\n",
      "Layer 180/181\n",
      "Layer 181/181\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy.linalg as la\n",
    "\n",
    "show_plots = False\n",
    "\n",
    "print 'Generating filter rankings...'\n",
    "\n",
    "filter_rankings = {}\n",
    "for layer_ii, layer in enumerate(model.model.layers):\n",
    "    if layer.get_weights():\n",
    "        wmat, bmat = layer.get_weights()\n",
    "        dist = np.zeros(wmat.shape[3])\n",
    "        for dim_j in range(wmat.shape[3]):\n",
    "            ijsum = 0\n",
    "            for dim_i in range(wmat.shape[2]):\n",
    "                Fij = wmat[:, :, dim_i, dim_j]\n",
    "                onenorm = la.norm(Fij, ord=1)\n",
    "                ijsum += onenorm\n",
    "            dist[dim_j] = ijsum\n",
    "        sort_inds = np.argsort(dist)\n",
    "        filter_rankings[layer.name] = sort_inds\n",
    "\n",
    "        relmax = np.max(dist - np.min(dist))\n",
    "        sorted_vals = (dist[sort_inds] - np.min(dist)) / relmax \n",
    "\n",
    "        if layer_ii % 10 is 0: \n",
    "            print '\\rLayer %d/%d' % (layer_ii + 1, len(model.model.layers))\n",
    "        if show_plots:\n",
    "            plt.title(layer.name)\n",
    "            plt.scatter(range(len(dist)), sorted_vals)\n",
    "\n",
    "            plt.show()\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
